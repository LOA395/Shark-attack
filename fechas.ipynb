{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHARK ATTACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos la base de datos y verificamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo de Excel usando Pandas\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15 Mar 2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Queensland</td>\n",
       "      <td>Bargara Beach</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Brooklyn Sauer</td>\n",
       "      <td>F</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark</td>\n",
       "      <td>Yahoo News, 3/15/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04 Mar 2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Old Man's, Waikiki</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Matthew White</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark 8'</td>\n",
       "      <td>Surfer, 3/6/2024F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02 Mar-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Rainbows, Oahu</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3' to 4' shark</td>\n",
       "      <td>Hawaii News Now, 3/4/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25 Feb-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Sandlnd Island, Jurian Bay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark</td>\n",
       "      <td>WA Today, 2/26/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14 Feb-2024</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>INDIA</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>Vaitarna River, Palghar District</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Vicky Suresh Govari</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>Bull shark, 7'</td>\n",
       "      <td>Times of India, 2/14/2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6965</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6969 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date    Year        Type    Country              State  \\\n",
       "0     15 Mar 2024  2024.0  Unprovoked  AUSTRALIA         Queensland   \n",
       "1     04 Mar 2024  2024.0  Unprovoked        USA             Hawaii   \n",
       "2     02 Mar-2024  2024.0  Unprovoked        USA             Hawaii   \n",
       "3     25 Feb-2024  2024.0  Unprovoked  AUSTRALIA  Western Australia   \n",
       "4     14 Feb-2024  2024.0  Unprovoked      INDIA        Maharashtra   \n",
       "...           ...     ...         ...        ...                ...   \n",
       "6964          NaN     NaN         NaN        NaN                NaN   \n",
       "6965          NaN     NaN         NaN        NaN                NaN   \n",
       "6966          NaN     NaN         NaN        NaN                NaN   \n",
       "6967          NaN     NaN         NaN        NaN                NaN   \n",
       "6968          NaN     NaN         NaN        NaN                NaN   \n",
       "\n",
       "                              Location  Activity                 Name  Sex  \\\n",
       "0                        Bargara Beach  Swimming       Brooklyn Sauer    F   \n",
       "1                   Old Man's, Waikiki   Surfing        Matthew White    M   \n",
       "2                       Rainbows, Oahu  Swimming                  NaN    F   \n",
       "3           Sandlnd Island, Jurian Bay       NaN               female    F   \n",
       "4     Vaitarna River, Palghar District   Fishing  Vicky Suresh Govari    M   \n",
       "...                                ...       ...                  ...  ...   \n",
       "6964                               NaN       NaN                  NaN  NaN   \n",
       "6965                               NaN       NaN                  NaN  NaN   \n",
       "6966                               NaN       NaN                  NaN  NaN   \n",
       "6967                               NaN       NaN                  NaN  NaN   \n",
       "6968                               NaN       NaN                  NaN  NaN   \n",
       "\n",
       "      Age  ...        Species                      Source  pdf  \\\n",
       "0      13  ...     Tiger shark      Yahoo News, 3/15/2024  NaN   \n",
       "1     NaN  ...  Tiger shark 8'          Surfer, 3/6/2024F  NaN   \n",
       "2      11  ...  3' to 4' shark  Hawaii News Now, 3/4/2024  NaN   \n",
       "3      46  ...     Tiger shark        WA Today, 2/26/2024  NaN   \n",
       "4      32  ...  Bull shark, 7'  Times of India, 2/14/2024  NaN   \n",
       "...   ...  ...             ...                        ...  ...   \n",
       "6964  NaN  ...             NaN                        NaN  NaN   \n",
       "6965  NaN  ...             NaN                        NaN  NaN   \n",
       "6966  NaN  ...             NaN                        NaN  NaN   \n",
       "6967  NaN  ...             NaN                        NaN  NaN   \n",
       "6968  NaN  ...             NaN                        NaN  NaN   \n",
       "\n",
       "                                           href formula href Case Number  \\\n",
       "0                                                   NaN  NaN         NaN   \n",
       "1                                                   NaN  NaN         NaN   \n",
       "2                                                   NaN  NaN         NaN   \n",
       "3                                                   NaN  NaN         NaN   \n",
       "4                                                   NaN  NaN         NaN   \n",
       "...                                                 ...  ...         ...   \n",
       "6964  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6965  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6966  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6967  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "6968  http://sharkattackfile.net/spreadsheets/pdf_di...  NaN         NaN   \n",
       "\n",
       "     Case Number.1 original order Unnamed: 21 Unnamed: 22  \n",
       "0              NaN            NaN         NaN         NaN  \n",
       "1              NaN            NaN         NaN         NaN  \n",
       "2              NaN            NaN         NaN         NaN  \n",
       "3              NaN            NaN         NaN         NaN  \n",
       "4              NaN            NaN         NaN         NaN  \n",
       "...            ...            ...         ...         ...  \n",
       "6964           NaN            NaN         NaN         NaN  \n",
       "6965           NaN            NaN         NaN         NaN  \n",
       "6966           NaN            NaN         NaN         NaN  \n",
       "6967           NaN            NaN         NaN         NaN  \n",
       "6968           NaN            NaN         NaN         NaN  \n",
       "\n",
       "[6969 rows x 23 columns]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores faltantes por columna:\n",
      "Date                25\n",
      "Year                27\n",
      "Type                43\n",
      "Country             75\n",
      "State              507\n",
      "Location           590\n",
      "Activity           611\n",
      "Name               245\n",
      "Sex                604\n",
      "Age               3019\n",
      "Injury              60\n",
      "Unnamed: 11        587\n",
      "Time              3551\n",
      "Species           3157\n",
      "Source              44\n",
      "pdf                170\n",
      "href formula       150\n",
      "href               173\n",
      "Case Number        171\n",
      "Case Number.1      172\n",
      "original order     170\n",
      "Unnamed: 21       6968\n",
      "Unnamed: 22       6967\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores faltantes\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos columnas sobrantes y valores unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eliminar columnas: pdf, href formula, href, Case Number.1, Case Number, original order, Unnamed: 21, Unnamed: 22, Source\n",
    "\n",
    "df.drop(['pdf', 'href formula', 'href', 'Case Number', 'Case Number.1', 'original order', 'Unnamed: 21', 'Unnamed: 22', 'Source'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas con más del 50% de valores faltantes\n",
    "missing_values_threshold = 0.5\n",
    "df = df.loc[:, df.isnull().mean() < missing_values_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura Ortiz\\AppData\\Local\\Temp\\ipykernel_2540\\4276926852.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"Unnamed: 11\": \"Died\"}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Renombrar columna unnamed: 11 por Died\n",
    "if \"Unnamed: 11\" in df.columns:\n",
    "    df.rename(columns={\"Unnamed: 11\": \"Died\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con más de 5 valores faltantes\n",
    "df = df.dropna(thresh=len(df.columns) - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         object\n",
       "Year        float64\n",
       "Type         object\n",
       "Country      object\n",
       "State        object\n",
       "Location     object\n",
       "Activity     object\n",
       "Name         object\n",
       "Sex          object\n",
       "Age          object\n",
       "Injury       object\n",
       "Died         object\n",
       "Species      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los valores numericos de Sex\n",
    "# df = df[df['Sex'].str.isdigit() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar Sex los valores nan, Unknown, ., por NAN\n",
    "df['Sex'] = df['Sex'].replace(['nan', 'Unknown', '.'], 'NaN')\n",
    "\n",
    "# Reemplazar 'M x 2' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'M x 2': 'M'})\n",
    "\n",
    "# Reemplazar 'lli' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'lli': 'M'})\n",
    "\n",
    "# Reemplazar ' M' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({' M': 'M'})\n",
    "\n",
    "# Reemplazar 'M ' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'M ': 'M'})\n",
    "\n",
    "# Reemplazar 'N' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'N': 'M'})\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Sex'] = df['Sex'].replace({''}, 'NaN')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['15 Mar 2024' '04 Mar 2024' '02 Mar-2024' ... '1900-1905' '1883-1889'\n",
      " '1845-1853']\n",
      "\n",
      "Valores faltantes:\n",
      "0\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       43\n",
      "State        452\n",
      "Location     534\n",
      "Activity     560\n",
      "Name         198\n",
      "Sex          552\n",
      "Age         2957\n",
      "Injury        28\n",
      "Died         549\n",
      "Species     3104\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Date'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Date'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laura Ortiz\\AppData\\Local\\Temp\\ipykernel_2540\\1929183097.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Date'] = df['Date'].str.replace('([^\\s]+\\s)', '')\n"
     ]
    }
   ],
   "source": [
    "# Eliminamos los valores letras de Date\n",
    "df = df[df['Date'].str.isdigit() == False]\n",
    "\n",
    "# Eliminamos Reported de Date\n",
    "df['Date'] = df['Date'].str.replace('Reported', '')\n",
    "\n",
    "# Dejamos solo el nombre del mes en Date\n",
    "df['Date'] = df['Date'].str.replace('([^\\s]+\\s)', '')\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Date'] = df['Date'].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['F' 'M' nan 'NaN']\n",
      "\n",
      "Valores faltantes:\n",
      "515\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         526\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Sex'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Sex'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['2024' 'Mar-2024' 'Feb-2024' ... '1900-1905' '1883-1889' '1845-1853']\n",
      "\n",
      "Valores faltantes:\n",
      "0\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         526\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos en la columna 'Date' y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Date'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Date'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "[nan 'N' 'Y' 'M' 'F' 'n' 'Nq' 'UNKNOWN' 2017 'Y x 2' ' N' 'y']\n",
      "\n",
      "Valores faltantes:\n",
      "526\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         526\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Died'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Died'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Died'] = df['Died'].str.upper()\n",
    "\n",
    "# Modificar Died los valores nan, UNKNOWN, M, F, Nq, 2017 , por NAN\n",
    "df['Died'] = df['Died'].replace(['nan', ' nan', 'UNKNOWN', 'M', 'F', 'Nq', '2017', '', ' 2017', '2017 '], 'NaN')\n",
    "\n",
    "# Reemplazar n, ' N' por 'N'\n",
    "df['Died'] = df['Died'].replace({'n': 'N', ' N': 'N'})\n",
    "\n",
    "# Reemplazar 'Y x 2', 'y'por 'Y'\n",
    "df['Died'] = df['Died'].replace({'Y x 2': 'Y', 'y': 'Y'})\n",
    "\n",
    "#Reemplazar 2017 por NAN\n",
    "df['Died'] = df['Died'].replace({'2017': 'NaN'})\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Died'] = df['Died'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar celdas NAN por NAN\n",
    "df['Died'] = df['Died'].replace({'NaN': 'NaN'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Unprovoked' ' Provoked' 'Provoked' 'Questionable' 'Watercraft'\n",
      " 'Sea Disaster' nan '?' 'Unconfirmed' 'Unverified' 'Invalid'\n",
      " 'Under investigation' 'Boat']\n",
      "\n",
      "Valores faltantes:\n",
      "18\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Type'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Type'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores faltantes en NaN\n",
    "df['Type'] = df['Type'].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date    Year Type       Country           State  \\\n",
      "191    01-Apr-2022  2022.0  NaN  SOUTH AFRICA             KZN   \n",
      "207    08-Feb-2022  2022.0  NaN    COSTA RICA      Guanacoste   \n",
      "228    16-Oct-2021  2021.0  NaN     AUSTRALIA      Queensland   \n",
      "233    10-Sep-2021  2021.0  NaN         EGYPT             NaN   \n",
      "254    21-Jul-2021  2021.0  NaN           USA         Florida   \n",
      "342    21-Oct-2020  2020.0  NaN           USA  North Carolina   \n",
      "347    21-Sep-2020  2020.0  NaN           USA          Hawaii   \n",
      "351    16-Sep-2020  2020.0  NaN           USA         Florida   \n",
      "354    08-Sep-2020  2020.0  NaN           USA         Florida   \n",
      "364    19-Aug-2020  2020.0  NaN           USA  South Carolina   \n",
      "393    04-Jun-2020  2020.0  NaN           USA        Delaware   \n",
      "403    29-Apr-2020  2020.0  NaN           USA      California   \n",
      "697    15-Sep-2017  2017.0  NaN         SAMOA    Upolu Island   \n",
      "997    27-Jul-2015  2015.0  NaN     AUSTRALIA        Victoria   \n",
      "5497   11-Sep-1936  1936.0  NaN       VIETNAM             NaN   \n",
      "6338   03-Mar-1890  1890.0  NaN        CEYLON             NaN   \n",
      "6819                   0.0  NaN         JAPAN             NaN   \n",
      "6820            BC     0.0  NaN          PERU          Paloma   \n",
      "\n",
      "                                  Location           Activity  \\\n",
      "191                                LaLucia                NaN   \n",
      "207                         Playa Del Coco             Diving   \n",
      "228                         Sudbury Island       Spearfishing   \n",
      "233                     Sidi Abdel Rahmen            Swimming   \n",
      "254       Near Patrick AFB, Brevard County                NaN   \n",
      "342          Emerald Isle, Carteret County            Surfing   \n",
      "347              Charley Young Beach, Maui           Swimming   \n",
      "351   Daytona Beach Shores, Volusia County           Swimming   \n",
      "354            Canaveral National Seashore       Surf fishing   \n",
      "364             Myrtle Beach, Horry County             Wading   \n",
      "393           Herring Point, Sussex County       Skimboarding   \n",
      "403      Moonlight Beach, San Diego County      Body Boarding   \n",
      "697                              Nofoali’i            Fishing   \n",
      "997                       Tyrendarra Beach            Surfing   \n",
      "5497                                Saigon  Wreck of a sampam   \n",
      "6338                                   NaN             Diving   \n",
      "6819                    Archeological site                NaN   \n",
      "6820                    Archeological site                NaN   \n",
      "\n",
      "                           Name Sex  Age  \\\n",
      "191   Two bodies washed ashore,   M  NaN   \n",
      "207                      female   F   50   \n",
      "228              Torrance Sambo   M   26   \n",
      "233                     Mohamed   M  NaN   \n",
      "254                  Katie Wood   F   35   \n",
      "342              Erik Martynuik   M  NaN   \n",
      "347                      female   F   61   \n",
      "351                 Eric Bowman   M   48   \n",
      "354                        male   M   54   \n",
      "364             Nicole Stowerss   F  NaN   \n",
      "393                  Holt Baker   M   12   \n",
      "403                        male   M   16   \n",
      "697                        male   M  NaN   \n",
      "997                        male   M   40   \n",
      "5497                     8 crew   M  NaN   \n",
      "6338              a pearl diver   M  NaN   \n",
      "6819                       male   M  NaN   \n",
      "6820                       male   M   17   \n",
      "\n",
      "                                                 Injury Died  \\\n",
      "191                     Possible drowing and scavenging  NaN   \n",
      "207                 Right forearm and left hand injured  NaN   \n",
      "228                                         Disappeared  NaN   \n",
      "233            Laceration to arm caused by metal object  NaN   \n",
      "254   Small laceration to ankle, shark involvement n...    N   \n",
      "342                         Laceration to knee and foot    N   \n",
      "347         Lacerations and puncture wounds to shoulder    N   \n",
      "351               Minor cuts and punctures to left foot    N   \n",
      "354   Hand bitten that was holding a fish PROVOKED I...    N   \n",
      "364                       Minor injury to arm by a fish    N   \n",
      "393                              Puncture wounds to leg    N   \n",
      "403                Minor injury to ankle from stingray     N   \n",
      "697                          Injuries to hands and legs    N   \n",
      "997                                      Injury to hand  NaN   \n",
      "5497                                              FATAL    Y   \n",
      "6338                                              FATAL    Y   \n",
      "6819                                              FATAL    Y   \n",
      "6820                                              FATAL    Y   \n",
      "\n",
      "                                               Species   \n",
      "191                                                 NaN  \n",
      "207                                      Bull shark, 3m  \n",
      "228                                                 NaN  \n",
      "233                               No shark invovlement   \n",
      "254                                                 NaN  \n",
      "342                     Shark involvement not confirmed  \n",
      "347                      Injuries not caused by a shark  \n",
      "351                     Shark involvement not confirmed  \n",
      "354                                      4' to 5' shark  \n",
      "364                                                 NaN  \n",
      "393   Shark involvement unconfirmed but considered p...  \n",
      "403                                                 NaN  \n",
      "697                                                 NaN  \n",
      "997                                                 NaN  \n",
      "5497                                                NaN  \n",
      "6338                                                NaN  \n",
      "6819                                                NaN  \n",
      "6820                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Visualizar los valores faltantes\n",
    "print(df[df['Type'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar Type los valores nan, '?', Invalid por NAN\n",
    "df['Type'] = df['Type'].replace(['nan', '?', 'Invalid'], 'NaN')  \n",
    "\n",
    "\n",
    "#Reemplazar ' Provoked' por 'Provoked'\n",
    "df['Type'] = df['Type'].replace({' Provoked': 'Provoked'})\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Type'] = df['Type'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar minusculas por mayusculas\n",
    "df['Type'] = df['Type'].str.upper()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Type'] = df['Type'].replace({''}, 'NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['AUSTRALIA' 'USA' 'INDIA' 'TRINIDAD' 'BAHAMAS' 'SOUTH AFRICA' 'MEXICO'\n",
      " 'NEW ZEALAND' 'EGYPT' 'Mexico' 'BELIZE' 'PHILIPPINES' 'Coral Sea' 'SPAIN'\n",
      " 'PORTUGAL' 'SAMOA' 'COLOMBIA' 'ECUADOR' 'FRENCH POLYNESIA'\n",
      " 'NEW CALEDONIA' 'TURKS and CaICOS' 'CUBA' 'BRAZIL' 'SEYCHELLES'\n",
      " 'ARGENTINA' 'FIJI' 'MeXICO' 'Maldives' 'South Africa' 'ENGLAND' 'JAPAN'\n",
      " 'INDONESIA' 'JAMAICA' 'MALDIVES' 'THAILAND' 'COLUMBIA' 'COSTA RICA'\n",
      " 'New Zealand' 'British Overseas Territory' 'CANADA' 'JORDAN'\n",
      " 'ST KITTS / NEVIS' 'ST MARTIN' 'PAPUA NEW GUINEA' 'REUNION ISLAND'\n",
      " 'ISRAEL' 'CHINA' 'IRELAND' 'ITALY' 'MALAYSIA' 'LIBYA' nan 'MAURITIUS'\n",
      " 'SOLOMON ISLANDS' 'ST HELENA, British overseas territory' 'COMOROS'\n",
      " 'REUNION' 'UNITED KINGDOM' 'UNITED ARAB EMIRATES' 'CAPE VERDE' 'Fiji'\n",
      " 'DOMINICAN REPUBLIC' 'CAYMAN ISLANDS' 'ARUBA' 'MOZAMBIQUE' 'PUERTO RICO'\n",
      " 'ATLANTIC OCEAN' 'GREECE' 'ST. MARTIN' 'FRANCE' 'TRINIDAD & TOBAGO'\n",
      " 'KIRIBATI' 'DIEGO GARCIA' 'TAIWAN' 'PALESTINIAN TERRITORIES' 'GUAM'\n",
      " 'NIGERIA' 'TONGA' 'SCOTLAND' 'CROATIA' 'SAUDI ARABIA' 'CHILE' 'ANTIGUA'\n",
      " 'KENYA' 'RUSSIA' 'TURKS & CAICOS' 'UNITED ARAB EMIRATES (UAE)' 'AZORES'\n",
      " 'SOUTH KOREA' 'MALTA' 'VIETNAM' 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS'\n",
      " 'BRITISH VIRGIN ISLANDS' 'NORWAY' 'YEMEN' 'GULF OF ADEN' 'Sierra Leone'\n",
      " 'ST. MAARTIN' 'GRAND CAYMAN' 'Seychelles' 'LIBERIA' 'VANUATU' 'MEXICO '\n",
      " 'HONDURAS' 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY' 'MICRONESIA'\n",
      " 'CARIBBEAN SEA' 'OKINAWA' 'TANZANIA' 'MARSHALL ISLANDS' 'SENEGAL'\n",
      " 'EGYPT / ISRAEL' 'NORTHERN ARABIAN SEA' 'HONG KONG' 'EL SALVADOR'\n",
      " 'ANGOLA' 'BERMUDA' 'TUNISIA' 'NAMIBIA' 'NORTH ATLANTIC OCEAN'\n",
      " 'SOUTH CHINA SEA' 'BANGLADESH' 'WESTERN SAMOA' 'PACIFIC OCEAN '\n",
      " 'BRITISH ISLES' 'PALAU' 'GRENADA' 'IRAQ' 'TURKEY' 'SINGAPORE'\n",
      " 'NEW BRITAIN' 'SUDAN' 'JOHNSTON ISLAND' 'SOUTH PACIFIC OCEAN'\n",
      " 'NEW GUINEA' 'RED SEA' 'NORTH PACIFIC OCEAN'\n",
      " 'FEDERATED STATES OF MICRONESIA' 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS'\n",
      " 'BRITISH WEST INDIES' 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF'\n",
      " 'RED SEA / INDIAN OCEAN' 'PACIFIC OCEAN' 'NORTH SEA' 'MALDIVE ISLANDS'\n",
      " 'AMERICAN SAMOA' 'ANDAMAN / NICOBAR ISLANDAS' 'GABON' 'MAYOTTE'\n",
      " 'NORTH ATLANTIC OCEAN ' 'MONTENEGRO' 'THE BALKANS' 'SUDAN?' 'IRAN'\n",
      " 'INDIAN OCEAN' 'GUATEMALA' 'NETHERLANDS ANTILLES'\n",
      " 'NORTHERN MARIANA ISLANDS' 'IRAN / IRAQ' 'JAVA' 'SIERRA LEONE'\n",
      " ' PHILIPPINES' 'NICARAGUA' 'CENTRAL PACIFIC' 'SOLOMON ISLANDS / VANUATU'\n",
      " 'SOUTHWEST PACIFIC OCEAN' 'BAY OF BENGAL' 'SLOVENIA' 'ICELAND'\n",
      " 'ITALY / CROATIA' 'BARBADOS' 'MONACO' 'GUYANA' 'HAITI' 'SAN DOMINGO'\n",
      " 'KUWAIT' 'YEMEN ' 'FALKLAND ISLANDS' 'CRETE' 'CYPRUS' 'EGYPT '\n",
      " 'WEST INDIES' 'BURMA' 'LEBANON' 'MARTINIQUE' 'BRITISH NEW GUINEA'\n",
      " 'CEYLON' 'GEORGIA' 'SYRIA' 'INDIAN OCEAN?' 'GUINEA'\n",
      " 'EQUATORIAL GUINEA / CAMEROON' 'COOK ISLANDS' 'TOBAGO' 'PERU' 'AFRICA'\n",
      " 'ALGERIA' 'Coast of AFRICA' 'TASMAN SEA' 'GHANA'\n",
      " 'Between PORTUGAL & INDIA' 'DJIBOUTI' 'BAHREIN' 'KOREA' 'RED SEA?'\n",
      " 'MEDITERRANEAN SEA' 'ASIA?' 'CEYLON (SRI LANKA)']\n",
      "\n",
      "Valores faltantes:\n",
      "40\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Country'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Country'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Country'] = df['Country'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['Country'] = df['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Queensland' 'Hawaii' 'Western Australia' 'Maharashtra' nan\n",
      " 'New  South Wales' 'Paradise Island' 'South Australia'\n",
      " 'Eastern Cape Province' 'Sonora' 'New South Wales' 'South Island'\n",
      " 'Guerrero' 'New Providence   Isoad' 'Jalisco' 'Grand  Bahama Island'\n",
      " 'Florida' 'Westerm Australia' 'North Island' 'Southern Red Sea'\n",
      " 'Quintana Roo' 'Belize District' 'California' 'South Carolina'\n",
      " 'South Sinai' 'Bolinao' 'North Carolina' 'Valencia' 'Norte'\n",
      " \"Savai'i island\" 'New York' 'San Andrés Island' 'Galapagos Islands'\n",
      " 'Red Sea Protectorate' 'Freeport' 'Tahiti' 'Poum' 'Providenciales Island'\n",
      " 'Lucayan Lucayan Archipelago' 'New Jersey' 'Mayabeque'\n",
      " 'Easten Cape Province' 'Artemisa' 'Pernambuco' 'Praslin Island'\n",
      " 'South Province' 'Patagonia' 'Taveuni Island' 'Gulf of California'\n",
      " 'Vaavu Atoll' 'KNZ' 'New South ales' 'Samoa' 'Texas' 'Louisiana'\n",
      " 'Mississippi' 'Western  Australia' 'Victoria' 'Western Cape Province'\n",
      " 'Cornwall' 'Noirth Carolina' 'Okinawa' 'Bali'\n",
      " 'Hurghada, Red Sea Governorate' 'Ambergris Cay' 'Bora Bora' 'Georgia'\n",
      " 'Phuket' 'Alabama' 'KZN' 'Isla De San Andres' 'Guanacoste'\n",
      " 'KwaZulu-Natal' 'São Paulo.' 'Turks and Caicos' 'Nova Scotia' 'Maryland'\n",
      " 'Chanthaburi Province' 'BAHAMAS' 'Galapagos' 'Aqaba' 'West Sussex'\n",
      " 'Nouville' 'Ambergris Key' 'Westmoreland Parish' 'Marquesas'\n",
      " 'Loyalty Islands' 'Maui' 'The Narrows' 'Raa Atoll' 'Oregon'\n",
      " ' Grand Bahama Island' 'Franklin County, Florida' 'Virgin Islands'\n",
      " 'Tasmania' 'Tuamotu Islands' 'Maine' 'Bahamas' 'Delaware' 'Abaco Islands'\n",
      " 'Muang district of Satun province, ' 'Canary Islands' 'Vanua Levu'\n",
      " 'Exumas' 'Southland' 'Phang Nga Province' 'Praslin' 'Central Province'\n",
      " 'Holquin' 'Moorea' 'Baja ' 'Saint-Gilles' 'Guam' 'Northern Territory '\n",
      " 'Cayman Islands' 'Rhode Island' 'Chatham Islands' 'Quinta Roo'\n",
      " 'Lucayan Archipelago' 'Bélep Islands' 'Noumea' 'Fernando de Noronha'\n",
      " 'Liaoning Province' 'New South Wales ' 'Upolo' 'St. Marys Parish'\n",
      " 'Massachusetts' 'County Cork' 'Chieti, Province' 'Guizhou Province'\n",
      " 'San Andres and Providencia Archipelago' 'The Exuma Cays' 'Colima'\n",
      " 'Hua Hin' 'Cocos Island' 'Alifu Alifu Atoll' 'New Providence' 'Alagoas'\n",
      " 'Boi Island, Victoria' 'Sepang' 'Holquin Province' 'Pamplemousses '\n",
      " ' Upolu Island' 'Shizuoka Prefecture' 'Castellón'\n",
      " 'New Providence District' '40 miles off Grand Bahama Island'\n",
      " 'Ascension Island' 'Majorca' 'Washington' 'Tabasco' 'Anjouan'\n",
      " 'Ibiza Island' 'South Devon' 'New Providence ' 'Sharjah, '\n",
      " 'Baja California Sur' 'Saint-Leu' 'Luzon Island' 'Tamaulipas'\n",
      " 'Saint-Andre' 'Bimini' 'Tuamotos' 'North Province'\n",
      " 'New Providence Island' 'Alicante Province' 'Hong Kong'\n",
      " 'Kochi Prefecture' 'Isla Providencia' 'Suez' 'Grand Terre'\n",
      " 'Boa Vista Island' 'Santa Catarina State' 'Altagracia Province'\n",
      " 'Grand Cayman' 'Balneário Camboriú' 'Fujairah Emirate'\n",
      " 'Grand Canary Island' 'Inhambane Province' 'Alicante' 'Guanacaste'\n",
      " 'Grand Bahama Island' 'Le Port' 'Rangiroa' 'Saint-Gilles-les-Bains'\n",
      " 'Sardinia' 'Sinaloa' 'Central Tuamotu' 'd’Étang-Salé' 'Granada'\n",
      " 'Cargados Carajos Shoals (St. Brandon)' 'Catalonia' 'West End'\n",
      " 'Atsumi peninsula' 'Palmyra Atoll' 'Wallis and Futuna'\n",
      " 'Baie de Sainte-Marie' 'Society Islands' 'Trinidad' 'Okinawa Prefecture'\n",
      " '740 miles SE of Tarawa Atoll' 'Southern District' 'Bay of Biscay'\n",
      " 'Exuma Islands' 'Saint-Paul' 'Taitung ' 'Kingston Parish'\n",
      " 'Santa Cruz Island' 'Tuamotus' 'Eleuthera' 'St. Catherine' 'Palawan'\n",
      " 'Mercury Islands' 'Delta' \"Vava'u\" 'Inner Hebrides' 'Saint Leu'\n",
      " 'Trois-Bassins' 'British Colombia' 'Saint-Benoit' 'Tabuk Province'\n",
      " 'Antofagasta Province' \"St John's\" 'Santa Elena' 'East New Britain'\n",
      " 'Bois-Blanc ' 'Moray' 'Puerto Rico' 'Samaná Province' 'Coast Province'\n",
      " 'Primorsky Krai' 'Peter the Great Bay, Khasan, Primorsky Krai (Far East)'\n",
      " 'Telyakovsky Bay, Khasan,  Primorsky Krai (Far East)' 'Sucre'\n",
      " 'Middle Caicos' 'Caicos Bank' 'San Andrés archipelago' 'Kedah'\n",
      " 'Umm al Qaywayan Province' 'Vitu Levu' 'South Sinai Peninsula'\n",
      " ' Loyalty Islands' 'Saint Gilles ' 'Virginia' \"Ha'api \"\n",
      " 'Western Province' 'Jeju Province' 'Binh Dinh Province'\n",
      " 'Antsiranana Province' 'Sinai Peninsula' 'Off Vanua Levu' 'Merizo'\n",
      " 'Rio Grande Do Sul' 'Dubai' 'Torres Strait' 'Eastern Province'\n",
      " 'Eastern Cape  Province' 'Maputo Province' 'Bocas' 'Fife' 'Devon'\n",
      " 'Makira-Ulawa Province' 'Mombasa' 'Catalunya' 'St. Johns Reef'\n",
      " 'Off Green Island' 'North Region' 'Batangas province' 'Strait of Malacca'\n",
      " 'Guantanamo Province' 'Maranhão' 'Red Sea' 'Batanes Provine' 'Luzon'\n",
      " 'Northern Territory' ' Split-Dalmatia Count,' 'North Devon'\n",
      " 'US Virgin Islands' 'San Carlos' 'Cabo San Lucas' 'Sussex' 'Bahia'\n",
      " 'Easter Ross' 'Guerro' 'Yasawa Islands' 'Northern Bahamas' 'Tokyo Bay'\n",
      " 'Baja California' 'Green Bay' 'Marovo Lagoon'\n",
      " 'Territory of Cocos (Keeling) Islands' 'Oslo Fjord' 'Kent' 'Bird Island'\n",
      " 'Providenciales' 'Bimini Islands' 'Muhafazat Hadramawt' 'Cook islans'\n",
      " 'Surigao del Norte' 'Between Somalia & Yemen' 'Ambergris Caye'\n",
      " 'Saint-Pierre' 'Kentucky' 'Andros Islands' 'Western Area'\n",
      " '300 miles from Antigua' '800 miles from land'\n",
      " '600 nm west of the Canary Islands' 'Simpson Bay' 'East Wall'\n",
      " 'Inner Islands' 'Shanghai' 'Malampa Province'\n",
      " \"South Ch'ungch'ong Province\" 'Bay Islands' 'New Mexico'\n",
      " 'Santa Isabel Province' 'Santiago de Cuba Province' 'Camaguey Province'\n",
      " 'Conservatória District' 'South Carolina ' 'Kuril Islands in the Pacific'\n",
      " 'Wakayama Prefecture' \"Nuku'alofa\" 'Saint-Benoît'\n",
      " 'South Island, near Karitane north of Dunedin' 'Rocha' 'Northlands'\n",
      " 'Anzoategui' 'Cook Islands' 'Tamil Nadu' 'Pearl Islands' 'Taveuni'\n",
      " 'Johnston Atoll' 'Baatan' 'Rio de Janeiro' 'Nueva Esparta'\n",
      " 'North Pacific coast' 'Caroline Islands' 'Cheshire'\n",
      " 'Louisiade Archipelago'\n",
      " 'KwaZulu-Natal between Port Edward and Port St Johns'\n",
      " 'Milne Bay Province' 'Cikobia Island (north of Vanua Levu)'\n",
      " 'Rayong Province' 'Zamboanga del Sur Province' 'Rio Grande de Norte'\n",
      " 'Off the western coast of peninsular Malaysia' 'New Brunswick'\n",
      " 'Miyako Island' 'Alaska' 'Minerva Reef' 'Madang Province'\n",
      " 'Worcestershire' 'Phang nga Province' 'Alinglaplap Atoll' 'Adriatic Sea'\n",
      " 'Ralik Chain' 'Grand Baie' \"L' Etang Salé-les-Bains\" 'Southern Japan'\n",
      " 'Cap Vert Peninsula' 'Marches region' 'Berry Islands' 'Transvaal' 'Gaza'\n",
      " \"Grand'Anse\" 'Miyako' \"L'Etang-Sale\" 'Chatham Islands '\n",
      " 'South Sinai, Gulf of Aqaba' 'Cat Cay' 'Missouri'\n",
      " '12 miles off the north coast' 'Saint-Paul '\n",
      " 'Chatham Islands, east of New  Zealand' 'Saint-Denis' 'Vava’u'\n",
      " 'Clearwater Bay' 'New Territories' 'Aichi Prefecture' 'Tafea Province'\n",
      " 'Kagoshima Prefecture' 'Saint-Joseph' 'Banaadir Region' 'La Libertad'\n",
      " 'Costa Blanca' 'Walkers Cay' 'On the Kowloon penisula, south of Sai Kung'\n",
      " 'Ehime Prefecture' 'Tongapatu Group' 'West Africa' 'Wakaya Island'\n",
      " 'North Carolina ' 'Mexico / Caribbean Sea' 'Antarctic Ocean'\n",
      " 'La Saline-les-Bains' 'Sea of Japan' 'Ligurian Sea' \"L'Etang-Salé\"\n",
      " 'Kowloon Peninsula' 'Port Shelter' 'Laucala Island' 'Sainte-Marie'\n",
      " 'Great Exuma Island' 'Sainte-Suzanne' 'Tuscany' 'Tyrrhenian Sea'\n",
      " 'Valpariso Province' 'Viscayan Sea' 'New Ireland' 'Manfredonia '\n",
      " 'Tokyo Prefecture' 'Saint-Louis' 'Mindoro' 'Between DR and Puerto Rico'\n",
      " 'Between Honiara & Isabel Island' 'Florida Straits' 'Gulf of Lyons'\n",
      " 'Cádiz' 'Sicily' 'Andikira Fokithes' 'Central Philippines'\n",
      " 'Northwest Italy' 'English Channel' 'Carolina coast'\n",
      " 'Kumamoto Prefecture' 'Saint-Philippe' 'Chungnam' 'Eronogo Region'\n",
      " 'Coquimbo' 'Pagasitikos Gulf' \"St. Mary's Parish\" 'Romblon Province'\n",
      " 'Lamu Archipelago' 'Los Vilos' 'Island of Kos' \"Ha'api\" 'Madeira Islands'\n",
      " 'Ho Ha Wan Marine Park' 'Southern Thailand' 'Golfo de Venezia'\n",
      " 'Ralik Archipelago' 'South China Sea 200 miles from Hong Kong'\n",
      " 'Reggio Calabria Province' 'Mirs Bay ' 'Genoa Province'\n",
      " 'Ganges-Brahmaputra delta' ' Split-Dalmatia County' 'Florida '\n",
      " 'Upolu Island' 'Istria County' 'Between Beira & Maputo'\n",
      " 'Inhambe Province' 'Namonuito Atoll' 'Eastern Caroline Islands'\n",
      " 'Western Caroline Islands (North Pacific Ocean)' 'Caribbean Sea'\n",
      " 'St. Andrew Parish' '200 nm southeast of Manila' 'Limpopo River'\n",
      " 'New Ireland Province' 'Basrah' 'Clarendon' 'Moro Gulf' 'Johor'\n",
      " 'Magdalena Department' 'Mafia Island' 'Gulf Province' 'Morobe Province'\n",
      " 'Rombion Province' 'Veracruz' 'Brindisi Province' 'Kagawa Prefecture'\n",
      " 'Liguria' 'Hamilton' 'Out Islands' 'Mugla Province' 'Gibraltar'\n",
      " 'New Britain' 'Bay of Maputo' 'Duke of York Islands'\n",
      " 'Primorje-Gorski Kotar County ' 'Taranto province' 'Northern Taiwan'\n",
      " 'Admiralty Islands, Manus Province' 'North Sumatra'\n",
      " \"250 miles southwest of O'ahu, Hawaii\" 'West coast' 'East Sepik'\n",
      " 'Near Bougainville (North Solomons)' 'Western Caroline Islands'\n",
      " 'East of the Gulf of Aqaba' 'Bougainville (North Solomons)' 'Victoria '\n",
      " 'Okayama Prefecture' 'San Blas' 'Connecticut' 'Lau Group'\n",
      " 'Caribbean Coast' 'Vita Levu' 'San Blas Islands' 'Puntarenas Province'\n",
      " 'Lomaloma, Lau' 'Between Southampton & Canary Islands'\n",
      " 'South Coast, East New Britain' ' Lau Province' 'Ysabel Island'\n",
      " 'Santo Domingo' 'San Blas coast' 'Thessaly' 'Lomaiviti  Island Group'\n",
      " 'Rodrigues' 'Manus Island' 'Pinas Bay' 'Grand Turk Island'\n",
      " 'Off coast of West Africa' 'Sharon' 'Antalya Province'\n",
      " 'Northern District' 'New Ireland Province, Bismarck Archipelago'\n",
      " 'Cyclades' 'Viti Levu' 'Off the Coromandel Peninsula, North Island'\n",
      " 'Madang' 'Guadalcanal Province' '10ºS, 142ºE' 'Kwajalein Atoll'\n",
      " 'East Flores' 'Guerrrero' 'Western Luzon Island' 'Shefa Province'\n",
      " '165  miles from Bermuda'\n",
      " '25 km off the coast of Iran & 483km from mouth of Persian Gulf'\n",
      " 'Venice Province' 'Sandaun Province' 'Anatolia'\n",
      " 'East New Britain Province' 'United Arab Emirates'\n",
      " 'Wake Island (EnenKio)' '19S, 178?E' 'Pennsylvania' '9.35N 79.35W'\n",
      " 'Roncador Bank' 'Western District' 'Enroute from Suez to Aden (Yemen)'\n",
      " '180 miles southeast of Okinawa' 'Eniwetok Atoll' 'Cap-Vert Peninsula'\n",
      " 'Delagoa Bay' 'In the English Channel ' 'Cook Strait'\n",
      " 'Unknown, treated at Wick, SCOTLAND' 'Corregidor Island' 'Paget'\n",
      " '33N, 68W' 'Casamance' 'Madang (WO)' 'Eastern  Province'\n",
      " 'Northwest of Viti Levu' 'Rigo subdistrict' 'Masbate'\n",
      " '400 miles southeast of Sri Lanka' 'Lomaiviti Province' 'Kadavu'\n",
      " 'Leyte Island' 'Orissa' 'Hokkaido Prefecture' 'North Palawan' 'Queaon'\n",
      " 'Istria' 'PANAMA' 'In the Gulf Stream ' 'Mersin Province' 'Guyamas'\n",
      " 'Between England & South Africa' 'Mindanao' ' Kikori River mouth'\n",
      " 'South Chungcheong Province' 'Ahirkapi coast' 'Tutuila Island'\n",
      " 'West New Britain Province' 'Primorje-Gorski Kotar County'\n",
      " 'Between Hawaii & Wake Island' 'Taipei Hsien' 'Ibaraki Prefecture'\n",
      " '1,000 miles east of Hawaii' 'Honiara' 'Yucatan Channel'\n",
      " 'Estuaire Province' 'Near Dakar, Cap Vert Peninsula'\n",
      " 'Near the Andaman & Nicobar Islands' 'Mozambique Channel' 'Tyrrenian Sea'\n",
      " 'Congreve Channel' 'St. Thomas Bay' 'Madeira' '1000 miles west of Hawaii'\n",
      " 'Izo Islands' ' Primorje-Gorski Kotar County' 'Open sea' 'Aden'\n",
      " 'New Ireland, Bismarck Archipelago' 'Isles del Rosario' 'Wake Island'\n",
      " 'Isle of Man' 'Zadar County' 'Nagasaki Prefecture' 'Slovenia'\n",
      " 'South shore ' 'Buenos Aires Province' 'Karun River'\n",
      " '330 to 350 miles east of Wake Island' 'Gulf of Panama' 'Genoa  Province'\n",
      " 'Abau Sub District, Central Province' 'Teramo' 'Red Sea State' 'Curacao'\n",
      " 'Port Louis Province' 'Montserrado' 'Bay of Maputu' 'Sofala Province'\n",
      " 'Salerno' 'Salerno Province' 'Corfu Island' 'Taranto' 'Naples Province'\n",
      " ' La Libertad' 'Sago Prefecture' 'Savona' 'Jakarta Harbour' 'Calabria'\n",
      " 'Shatt-el-Arab River' 'Shatt-al-Arab River' 'Shat-Al-Arab River'\n",
      " 'Between Kwajalein Atoll & Johnston Island' 'Attica' 'Adana Province'\n",
      " 'Bandar Ma’shur sea inlet' 'Saipan' 'Carpathian Sea' 'Kwajalein'\n",
      " 'Khuzestan Province' 'Dar-es-Salaam ' 'Ryukyu' ' North Carolina'\n",
      " 'In transit between Tinian and Leyte' 'Northern Java' 'Tel Aviv'\n",
      " '300 miles east of Luzon' 'Bernardino Strait near Gulf of Leyte'\n",
      " 'Off Samar Island in the Gulf of Leyte' 'Lake Nicaragua (fresh water)'\n",
      " 'Near the Fiji Islands' '40 miles south of Naples '\n",
      " 'Northwest of Papua New Guinea' 'Between Hawaii and U.S.A.'\n",
      " 'Off South American coast' 'Makora-Ulawa Province' '04.05N-13.23W'\n",
      " 'Midway Atoll' '300 miles east of St. Thomas (Virgin Islands)'\n",
      " 'West of Ceylon (Sri  Lanka)' 'Camiguin Island' 'Off Libya'\n",
      " 'North of Pernambuco, Brazil' 'Off coast of Ecuador' 'Trelawney Province'\n",
      " 'In Convoy OB 274' 'Panama Bay (Pacific Ocean)' 'Torres Strait '\n",
      " 'North China' 'Lower San Juan River' 'Nicoya Peninsula' 'Basrah City'\n",
      " 'West Bengal' 'Queensland ' 'Argyllshire' 'Arran' 'Argyll'\n",
      " 'Colon Province' 'Fishing Grounds' 'Newfoundland' 'Isle of Wight'\n",
      " 'Makira-Uluwa Province' 'Northern (Oro) Province' 'Herzliyah'\n",
      " 'Elqui Province' 'Istanbul' 'St Michael Parish' 'Havana Province'\n",
      " 'Barlavento Islands' 'Viti Levu Island' 'Bay of Fundy' 'Manila'\n",
      " 'French Southern Territories' 'Black River' 'Limón Province'\n",
      " 'Phoenix Islands' 'Cienfuegos Province' 'Santiago Island'\n",
      " 'Near Puntarenas' 'Porto Seguro' 'Salinas Bay'\n",
      " 'Golfo di Genova in the Ligurian Sea' 'Sants-Montjic'\n",
      " 'South of the Equator ' 'Bay of Monaco' 'Valencia ' 'Vancouver'\n",
      " '2 to 3 miles off Taboguilla Island, Pacific Ocean' 'Dorset'\n",
      " '150 miles offshore' 'Galica' 'Demerara County' 'Vera Cruz' ' Manila Bay'\n",
      " 'Lucy' 'East Yorkshire' 'Cape Haitien' 'Leyte' 'Halifax' 'Turtle Bogue'\n",
      " '60 miles north of San Domingo in the West Indies' 'Colon' 'Off Ireland'\n",
      " 'Gran Canaria' 'Apolima Strait' 'Essequibo' 'Lagos ' 'Viti Levu group'\n",
      " 'Málaga ' 'Georges Bank' 'Zambesi River' 'Colón Province'\n",
      " '30 nm from Singapore' 'Andalucia' 'Sfax' 'South Atlantic Ocean'\n",
      " 'Galicia' 'Gulf of Suez' 'Java' 'Tiburon Peninsula' 'Oaxaca'\n",
      " 'Harare Province' 'Maluku Province' 'Suez Canal' ' Nusa Tenggara'\n",
      " 'Between Noumea & Sydney' 'Villa Clara Province' 'Ancona Province'\n",
      " 'Rio San Juan' 'Mediterranean Sea' 'Southern Cyprus' 'Syracuse'\n",
      " 'Western Viscayas' 'Mindoro Occidental' 'Negros ' 'Imperia Province'\n",
      " 'Muala' 'East coast' 'Ratak ' 'Socotra Islands' 'Moluccas'\n",
      " 'Bocas del Toro' 'Provence' 'Bay of Campeche' 'Rangoon' 'Bay of Bengal'\n",
      " 'Bayelsa State' 'South Island?' 'Norfolk Island' 'Brittany'\n",
      " 'Line Islands' 'Woodlark Islands' 'Munxar Reef' 'Northern Peloponnese'\n",
      " 'Between Perth & Colombo' 'Gujarat' 'Cortés' ' New Jersey'\n",
      " \"Côte d'Azur  \" 'Maldonado coast' 'Western Banks' 'Andaman Islands'\n",
      " 'East Java' 'Off the coast of West Africa' 'Misamis Oriental'\n",
      " 'Strait of Messina' 'Hoogly River' 'Cyclades archipelago' 'Veracruz '\n",
      " 'Gilbert Islands' 'Lomaiviti Provine' 'Off the coast of South America'\n",
      " '22ºN, 88ºE' 'Alpes Maritime' 'Edinburgh' 'Eastern Catalona'\n",
      " '300 miles east of Mauritius' 'Foveaux Strait' 'Conakry Region' 'Corfu'\n",
      " 'Malaga' 'Fernando Po Island' 'Mangaia Island' 'New York ' 'Corfu '\n",
      " 'Between Australia & USA' 'Tongatapu' 'Norfolk' 'Island of St. Thomas'\n",
      " 'Matanzas Province (north coast)' 'Cumberland' 'Sanma Province'\n",
      " \"35º39 : 165º8'\" 'CUBA' 'Western Area ' 'Paraiba' 'Cape Coast'\n",
      " 'Rivers State' 'St Helena' 'Southwest coast' \"Côte d'Azur \"\n",
      " 'Nice & Marseilles' 'Magarita or Cubagua Islands' 'Yucatan' 'Ionian Sea'\n",
      " 'Piraeus' 'Off Thessaly' 'Paloma' 'Bocas del Toro Province' 'Rocha '\n",
      " 'Gulf of Tadjoura' 'Cyrenaica' 'Northern Province' 'Los Roques  Islands'\n",
      " 'Dodecanese Islands' 'Malaita Province' 'South Korea'\n",
      " 'Milne Bay  Province' 'Island of Volos' 'Amirante Islands'\n",
      " 'Kadavu Island Group' 'Toamasina Province' 'Riau Province' 'Bikini Atoll'\n",
      " 'New Georgia' 'Between New Ireland & New Britain'\n",
      " 'Ba Ria-Vung Tau  Province' 'Moala Island']\n",
      "\n",
      "Valores faltantes:\n",
      "419\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['State'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['State'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['State'] = df['State'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['State'] = df['State'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['State'] = df['State'].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Bargara Beach' \"Old Man's, Waikiki\" 'Rainbows, Oahu' ...\n",
      " 'Ocracoke Inlet' 'Panama Bay 8ºN, 79ºW'\n",
      " 'Below the English fort, Trincomalee']\n",
      "\n",
      "Valores faltantes:\n",
      "482\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Location'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Location'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Reemplazar minisculas por mayusculas\n",
    "df['Location'] = df['Location'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['Location'] = df['Location'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Location'] = df['Location'].replace({''}, 'NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Swimming' 'Surfing' nan ...\n",
      " 'Crew swimming alongside their anchored ship' '4 men were bathing'\n",
      " 'Wreck of  large double sailing canoe']\n",
      "\n",
      "Valores faltantes:\n",
      "501\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity     501\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Activity'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Activity'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Activity'] = df['Activity'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['Activity'] = df['Activity'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Activity'] = df['Activity'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar los valores que no sean 'SURFING', 'SWIMMING' o 'FISHING' por NaN\n",
    "valid_activities = ['SURFING', 'SWIMMING', 'FISHING']\n",
    "df['Activity'] = df['Activity'].apply(lambda x: x if x in valid_activities else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['13' nan '11' '46' '32' '29' '10' '64' '62' '39' '22' '15' '16' '21' '66'\n",
      " '52' '20' '44' '26' '47' '55' '30' '59' '8' '50' '45' '34' '38' '30s'\n",
      " '37' '9' '19' '20/30' '35' '65' '20s' '77' '60' 38 '49' '42' '!2' '24'\n",
      " '73' '25' '18' '50s' '58' '67' '17' '14' '6' '41' '53' '68' '43' '40'\n",
      " '51' '31' 39 26 58 51 14 17 10 13 33 16 40 49 41 60 28 '40s' 68 35 62\n",
      " 'teen' 20 8 22 32 56 'Teen' 12 21 42 36 18 37 50 'M' 9 24 15 11 27 57 34\n",
      " 25 '!6' 31 64 '!!' 47 55 19 7 71 48 59 53 54 75 '45 and 15' 46 61 73 52\n",
      " 29 30 70 23 4 63 45 44 '28 & 22' '22, 57, 31' '60s' \"20's\" 43 65 67 74\n",
      " '9 & 60' 'a minor' 6 69 3 82 66 72 '23' '12' '36' '63' '71' '48' '70'\n",
      " '18 months' '57' '7' '28' '33' '61' '74' '27' '3' '56' '28 & 26' '5' '54'\n",
      " '86' '18 or 20' '12 or 13' '46 & 34' '28, 23 & 30' 'Teens' 77 '36 & 26'\n",
      " '8 or 10' 84 '\\xa0 ' ' ' '30 or 36' '6½' '21 & ?' '33 or 37' 'mid-30s'\n",
      " '23 & 20' 5 ' 30' '7      &    31' ' 28' '20?' \"60's\" '69' '32 & 30'\n",
      " '16 to 18' '87' 'Elderly' 'mid-20s' 'Ca. 33' '74 ' '45 ' '21 or 26' '20 '\n",
      " '>50' '18 to 22' 'adult' '9 & 12' '? & 19' '9 months' '25 to 35'\n",
      " '23 & 26' 1 '(adult)' '33 & 37' '25 or 28' '37, 67, 35, 27,  ? & 27'\n",
      " '21, 34,24 & 35' '30 & 32' '50 & 30' '17 & 35' 'X' '\"middle-age\"'\n",
      " '13 or 18' '33 & 26' '4' 'MAKE LINE GREEN' ' 43' '81' '\"young\"' '7 or 8'\n",
      " 78 '17 & 16' 'F' 'Both 11' '9 or 10' 'young' '36 & 23' '  ' '78' 'A.M.'\n",
      " '?    &   14' '10 or 12' '31 or 33' '2½' '1' '13 or 14']\n",
      "\n",
      "Valores faltantes:\n",
      "2726\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity    4036\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         2726\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Age'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Age'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar espacios en las celdas\n",
    "df['Age'] = df['Age'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Age'] = df['Age'].replace({''}, 'NaN')\n",
    "\n",
    "# Convertir la columna 'Age' a numérica, con valores no numéricos convertidos a NaN\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Minor injuries to back, abdomen and legs'\n",
      " 'No injury, shark bit surfboard' 'Lacerations to left foot' ...\n",
      " 'FATAL, leg stripped of flesh  '\n",
      " 'FATAL, knocked overboard by tail of shark & carried off by shark '\n",
      " 'FATAL. \"Shark bit him in half, carrying away the lower extremities\" ']\n",
      "\n",
      "Valores faltantes:\n",
      "25\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity    4036\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         4823\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Injury'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Injury'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar espacios en las celdas\n",
    "df['Injury'] = df['Injury'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Injury'] = df['Injury'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar minusculas por mayusculas\n",
    "df['Injury'] = df['Injury'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Tiger shark' \"Tiger shark 8'\" \"3' to 4' shark\" ... \"12' tiger shark\"\n",
      " 'Blue pointers'\n",
      " 'Said to involve a grey nurse shark that leapt out of the water and  seized the boy but species identification is questionable']\n",
      "\n",
      "Valores faltantes:\n",
      "2914\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity    4036\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         4823\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Species '].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Species '].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Species '] = df['Species '].str.upper()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Species '] = df['Species '].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['TIGER SHARK' \"TIGER SHARK 8'\" \"3' TO 4' SHARK\" ... \"12' TIGER SHARK\"\n",
      " 'BLUE POINTERS'\n",
      " 'SAID TO INVOLVE A GREY NURSE SHARK THAT LEAPT OUT OF THE WATER AND  SEIZED THE BOY BUT SPECIES IDENTIFICATION IS QUESTIONABLE']\n",
      "\n",
      "Valores faltantes:\n",
      "2914\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       40\n",
      "State        419\n",
      "Location     482\n",
      "Activity    4036\n",
      "Name         187\n",
      "Sex          515\n",
      "Age         4823\n",
      "Injury        25\n",
      "Died         527\n",
      "Species     2914\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Valores unicos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Species '].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Species '].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIMINAMOS DUPLICADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Year           2\n",
       "Type          18\n",
       "Country       40\n",
       "State        419\n",
       "Location     482\n",
       "Activity    4034\n",
       "Name         187\n",
       "Sex          515\n",
       "Age         4821\n",
       "Injury        25\n",
       "Died         527\n",
       "Species     2913\n",
       "dtype: int64"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos las filas de 1642 para atras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6623, 13)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Year           2\n",
       "Type          18\n",
       "Country       40\n",
       "State        419\n",
       "Location     482\n",
       "Activity    4034\n",
       "Name         187\n",
       "Sex          515\n",
       "Age         4821\n",
       "Injury        25\n",
       "Died         527\n",
       "Species     2913\n",
       "dtype: int64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas de menos del year 1700\n",
    "df = df[df['Year'] >= 1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6483, 13)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Year           0\n",
       "Type          16\n",
       "Country       36\n",
       "State        391\n",
       "Location     443\n",
       "Activity    3919\n",
       "Name         182\n",
       "Sex          505\n",
       "Age         4688\n",
       "Injury        21\n",
       "Died         523\n",
       "Species     2813\n",
       "dtype: int64"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4393     26-Jan-1963\n",
       "1504     31-Jul-2011\n",
       "2566        May-2001\n",
       "3392     12-Jul-1987\n",
       "4328     01-Feb-1964\n",
       "837      05-Sep-2016\n",
       "4400        Jan-1963\n",
       "6314     19-May-1892\n",
       "6356        Dec-1888\n",
       "6647            1854\n",
       "5220     24-Dec-1946\n",
       "3207     07-Jul-1991\n",
       "1063     09-Feb-2015\n",
       "2940     10-Jan-1996\n",
       "928      25-Jan-2016\n",
       "5780     03-Jul-1926\n",
       "115      05-Jan-2023\n",
       "2275     26-Jun-2004\n",
       "120         Dec-2022\n",
       "6276     15-Mar-1895\n",
       "5121           1950s\n",
       "3189     04-Dec-1991\n",
       "1008     04-Jul-2015\n",
       "992      18-Aug-2015\n",
       "1929     29-Oct-2007\n",
       "5074     22-May-1951\n",
       "3529     25-Dec-1983\n",
       "3676     17-Oct-1980\n",
       "5282     14-Mar-1944\n",
       "439      23-Nov-2019\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar valores unicos y visualizarlos\n",
    "df['Date'].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar espacios en las celdas\n",
    "\n",
    "df['Date'] = df['Date'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplazar espacios por guiones\n",
    "df['Date'] = df['Date'].apply(lambda x: x.replace(' ', '-') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3093    21-Aug-1993\n",
       "4764    05-Oct-1958\n",
       "1131    09-Aug-2014\n",
       "4515    16-Jul-1961\n",
       "3880    23-Aug-1974\n",
       "3518    10-Mar-1984\n",
       "5781    18-May-1926\n",
       "6519    15-Jun-1874\n",
       "4215    25-Jan-1966\n",
       "4798    09-Jan-1958\n",
       "6492    11-Mar-1877\n",
       "623            2018\n",
       "3646    12-Jun-1981\n",
       "3369    12-Feb-1988\n",
       "1576    01-Dec-2010\n",
       "996     28-Jul-2015\n",
       "5012       Mar-1953\n",
       "1391    20-Jun-2012\n",
       "4244    02-Jul-1965\n",
       "3840    23-Jul-1975\n",
       "46             2023\n",
       "5628    27-Jan-1932\n",
       "5621    12-May-1932\n",
       "1005    10-Jul-2015\n",
       "3433       Aug-1986\n",
       "2301    28-Mar-2004\n",
       "1085    15-Dec-2014\n",
       "2085    20-Jun-2006\n",
       "4132    20-Sep-1967\n",
       "6538       Aug-1871\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar valores unicos y visualizarlos\n",
    "df['Date'].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para reemplazar 'Reported-' por 'NaN', 'Late-' por 'NaN', 'Early-' por 'NaN'\n",
    "\n",
    "df['Date'] = df['Date'].str.replace('^(Reported-|Late-|Early-)', '', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the day if the length of the split parts is 3 (i.e., day, month, year)\n",
    "def quitar_dia(x):\n",
    "    parts = x.split('-')\n",
    "    if len(parts) == 3:\n",
    "        return '-'.join(parts[1:])  # Return the string without the first element (the day)\n",
    "    return x  # Return the original string if it's not in the expected format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = df['Date'].apply(lambda x: quitar_dia(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6784    Oct-1753\n",
       "5821    Jan-1924\n",
       "362     Aug-2020\n",
       "1640    May-2010\n",
       "3185    Jan-1992\n",
       "5365    Nov-1941\n",
       "6357    Oct-1888\n",
       "4633    Apr-1960\n",
       "6109    Apr-1906\n",
       "5767    Jan-1927\n",
       "3020    Dec-1994\n",
       "2374    Jul-2003\n",
       "3284    Sep-1989\n",
       "4475    Jan-1962\n",
       "6023    Apr-1911\n",
       "1017    Jun-2015\n",
       "4976    Feb-1954\n",
       "48      Aug-2023\n",
       "3173    Mar-1992\n",
       "6356    Dec-1888\n",
       "5763    Feb-1927\n",
       "1306    Mar-2013\n",
       "4610    Jun-1960\n",
       "3747    Apr-1978\n",
       "3773    Apr-1977\n",
       "5780    Jul-1926\n",
       "1653    Feb-2010\n",
       "3172    Apr-1992\n",
       "2363    Sep-2003\n",
       "373     Jul-2020\n",
       "Name: Date, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'],format ='%b-%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date        datetime64[ns]\n",
       "Year               float64\n",
       "Type                object\n",
       "Country             object\n",
       "State               object\n",
       "Location            object\n",
       "Activity            object\n",
       "Name                object\n",
       "Sex                 object\n",
       "Age                float64\n",
       "Injury              object\n",
       "Died                object\n",
       "Species             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6625   1858-03-01\n",
       "5645   1931-07-01\n",
       "6104   1906-09-01\n",
       "5574   1934-04-01\n",
       "1533   2011-05-01\n",
       "2621   2000-09-01\n",
       "4508   1961-09-01\n",
       "1918   2007-12-01\n",
       "107    2023-02-01\n",
       "957    2015-10-01\n",
       "767    2017-04-01\n",
       "4626   1960-04-01\n",
       "2366   2003-08-01\n",
       "3059   1994-04-01\n",
       "4195   1966-07-01\n",
       "2529   2001-08-01\n",
       "1040   2015-05-01\n",
       "505    2019-05-01\n",
       "5472   1937-08-01\n",
       "1829   2008-08-01\n",
       "4351   1963-12-01\n",
       "2065   2006-07-01\n",
       "122    2022-12-01\n",
       "2237   2004-11-01\n",
       "3856   1975-03-01\n",
       "2244   2004-10-01\n",
       "6360   1888-07-01\n",
       "5074   1951-05-01\n",
       "143    2022-08-01\n",
       "743           NaT\n",
       "Name: Date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'].isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
