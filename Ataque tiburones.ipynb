{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHARK ATTACK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos la base de datos y verificamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el archivo de Excel usando Pandas\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores faltantes por columna:\n",
      "Date                25\n",
      "Year                27\n",
      "Type                43\n",
      "Country             75\n",
      "State              507\n",
      "Location           590\n",
      "Activity           611\n",
      "Name               245\n",
      "Sex                604\n",
      "Age               3019\n",
      "Injury              60\n",
      "Unnamed: 11        587\n",
      "Time              3551\n",
      "Species           3157\n",
      "Source              44\n",
      "pdf                170\n",
      "href formula       150\n",
      "href               173\n",
      "Case Number        171\n",
      "Case Number.1      172\n",
      "original order     170\n",
      "Unnamed: 21       6968\n",
      "Unnamed: 22       6967\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores faltantes\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos columnas sobrantes y valores unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eliminar columnas: pdf, href formula, href, Case Number.1, Case Number, original order, Unnamed: 21, Unnamed: 22, Source\n",
    "\n",
    "df.drop(['pdf', 'href formula', 'href', 'Case Number', 'Case Number.1', 'original order', 'Unnamed: 21', 'Unnamed: 22', 'Source'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas con más del 50% de valores faltantes\n",
    "missing_values_threshold = 0.5\n",
    "df = df.loc[:, df.isnull().mean() < missing_values_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columna unnamed: 11 por Died\n",
    "if \"Unnamed: 11\" in df.columns:\n",
    "    df.rename(columns={\"Unnamed: 11\": \"Died\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con más de 5 valores faltantes\n",
    "df = df.dropna(thresh=len(df.columns) - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los valores numericos de Sex\n",
    "df = df[df['Sex'].str.isdigit() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar Sex los valores nan, Unknown, ., por NAN\n",
    "df['Sex'] = df['Sex'].replace(['nan', 'Unknown', '.'], 'NaN')\n",
    "\n",
    "# Reemplazar 'M x 2' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'M x 2': 'M'})\n",
    "\n",
    "# Reemplazar 'lli' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'lli': 'M'})\n",
    "\n",
    "# Reemplazar ' M' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({' M': 'M'})\n",
    "\n",
    "# Reemplazar 'M ' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'M ': 'M'})\n",
    "\n",
    "# Reemplazar 'N' por 'M'\n",
    "df['Sex'] = df['Sex'].replace({'N': 'M'})\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Sex'] = df['Sex'].replace({''}, 'NaN')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['15 Mar 2024' '04 Mar 2024' '02 Mar-2024' ... '26-Mar-1703' '1700s'\n",
      " 'Late 1600s  1728']\n",
      "\n",
      "Valores faltantes:\n",
      "0\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           0\n",
      "Type          16\n",
      "Country       35\n",
      "State        356\n",
      "Location     404\n",
      "Activity    3556\n",
      "Name          64\n",
      "Sex            0\n",
      "Age         4201\n",
      "Injury        13\n",
      "Died         458\n",
      "Species     2610\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Date'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Date'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los valores letras de Date\n",
    "df = df[df['Date'].str.isdigit() == False]\n",
    "\n",
    "# Eliminamos Reported de Date\n",
    "df['Date'] = df['Date'].str.replace('Reported', '')\n",
    "\n",
    "# Dejamos solo el nombre del mes en Date\n",
    "df['Date'] = df['Date'].str.replace('([^\\s]+\\s)', '')\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Date'] = df['Date'].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['F' 'M' 'NaN']\n",
      "\n",
      "Valores faltantes:\n",
      "0\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         460\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Sex'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Sex'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['15 Mar 2024' '04 Mar 2024' '02 Mar-2024' ... '1900-1905' '1883-1889'\n",
      " '1845-1853']\n",
      "\n",
      "Valores faltantes:\n",
      "0\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         460\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos en la columna 'Date' y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Date'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Date'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "[nan 'N' 'Y' 'M' 'F' 'n' 'Nq' 'UNKNOWN' 2017 'Y x 2' ' N' 'y']\n",
      "\n",
      "Valores faltantes:\n",
      "460\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         460\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Died'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Died'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Died'] = df['Died'].str.upper()\n",
    "\n",
    "# Modificar Died los valores nan, UNKNOWN, M, F, Nq, 2017 , por NAN\n",
    "df['Died'] = df['Died'].replace(['nan', ' nan', 'UNKNOWN', 'M', 'F', 'Nq', '2017', '', ' 2017', '2017 '], 'NaN')\n",
    "\n",
    "# Reemplazar n, ' N' por 'N'\n",
    "df['Died'] = df['Died'].replace({'n': 'N', ' N': 'N'})\n",
    "\n",
    "# Reemplazar 'Y x 2', 'y'por 'Y'\n",
    "df['Died'] = df['Died'].replace({'Y x 2': 'Y', 'y': 'Y'})\n",
    "\n",
    "#Reemplazar 2017 por NAN\n",
    "df['Died'] = df['Died'].replace({'2017': 'NaN'})\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Died'] = df['Died'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar celdas NAN por NAN\n",
    "df['Died'] = df['Died'].replace({'NaN': 'NaN'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Unprovoked' ' Provoked' 'Provoked' 'Questionable' 'Watercraft'\n",
      " 'Sea Disaster' nan '?' 'Unverified' 'Invalid' 'Under investigation']\n",
      "\n",
      "Valores faltantes:\n",
      "18\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Type'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Type'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los valores faltantes en NaN\n",
    "df['Type'] = df['Type'].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Date    Year Type       Country           State  \\\n",
      "191     01-Apr-2022  2022.0  NaN  SOUTH AFRICA             KZN   \n",
      "207     08-Feb-2022  2022.0  NaN    COSTA RICA      Guanacoste   \n",
      "228     16-Oct-2021  2021.0  NaN     AUSTRALIA      Queensland   \n",
      "233     10-Sep-2021  2021.0  NaN         EGYPT             NaN   \n",
      "254     21-Jul-2021  2021.0  NaN           USA         Florida   \n",
      "342     21-Oct-2020  2020.0  NaN           USA  North Carolina   \n",
      "347     21-Sep-2020  2020.0  NaN           USA          Hawaii   \n",
      "351     16-Sep-2020  2020.0  NaN           USA         Florida   \n",
      "354     08-Sep-2020  2020.0  NaN           USA         Florida   \n",
      "364     19-Aug-2020  2020.0  NaN           USA  South Carolina   \n",
      "393     04-Jun-2020  2020.0  NaN           USA        Delaware   \n",
      "403     29-Apr-2020  2020.0  NaN           USA      California   \n",
      "697     15-Sep-2017  2017.0  NaN         SAMOA    Upolu Island   \n",
      "997     27-Jul-2015  2015.0  NaN     AUSTRALIA        Victoria   \n",
      "5497    11-Sep-1936  1936.0  NaN       VIETNAM             NaN   \n",
      "6338    03-Mar-1890  1890.0  NaN        CEYLON             NaN   \n",
      "6819  Ca. 1010  BC      0.0  NaN         JAPAN             NaN   \n",
      "6820     Ca 4000 BC     0.0  NaN          PERU          Paloma   \n",
      "\n",
      "                                  Location           Activity  \\\n",
      "191                                LaLucia                NaN   \n",
      "207                         Playa Del Coco             Diving   \n",
      "228                         Sudbury Island       Spearfishing   \n",
      "233                     Sidi Abdel Rahmen            Swimming   \n",
      "254       Near Patrick AFB, Brevard County                NaN   \n",
      "342          Emerald Isle, Carteret County            Surfing   \n",
      "347              Charley Young Beach, Maui           Swimming   \n",
      "351   Daytona Beach Shores, Volusia County           Swimming   \n",
      "354            Canaveral National Seashore       Surf fishing   \n",
      "364             Myrtle Beach, Horry County             Wading   \n",
      "393           Herring Point, Sussex County       Skimboarding   \n",
      "403      Moonlight Beach, San Diego County      Body Boarding   \n",
      "697                              Nofoali’i            Fishing   \n",
      "997                       Tyrendarra Beach            Surfing   \n",
      "5497                                Saigon  Wreck of a sampam   \n",
      "6338                                   NaN             Diving   \n",
      "6819                    Archeological site                NaN   \n",
      "6820                    Archeological site                NaN   \n",
      "\n",
      "                           Name Sex  Age  \\\n",
      "191   Two bodies washed ashore,   M  NaN   \n",
      "207                      female   F   50   \n",
      "228              Torrance Sambo   M   26   \n",
      "233                     Mohamed   M  NaN   \n",
      "254                  Katie Wood   F   35   \n",
      "342              Erik Martynuik   M  NaN   \n",
      "347                      female   F   61   \n",
      "351                 Eric Bowman   M   48   \n",
      "354                        male   M   54   \n",
      "364             Nicole Stowerss   F  NaN   \n",
      "393                  Holt Baker   M   12   \n",
      "403                        male   M   16   \n",
      "697                        male   M  NaN   \n",
      "997                        male   M   40   \n",
      "5497                     8 crew   M  NaN   \n",
      "6338              a pearl diver   M  NaN   \n",
      "6819                       male   M  NaN   \n",
      "6820                       male   M   17   \n",
      "\n",
      "                                                 Injury Died  \\\n",
      "191                     Possible drowing and scavenging  NaN   \n",
      "207                 Right forearm and left hand injured  NaN   \n",
      "228                                         Disappeared  NaN   \n",
      "233            Laceration to arm caused by metal object  NaN   \n",
      "254   Small laceration to ankle, shark involvement n...    N   \n",
      "342                         Laceration to knee and foot    N   \n",
      "347         Lacerations and puncture wounds to shoulder    N   \n",
      "351               Minor cuts and punctures to left foot    N   \n",
      "354   Hand bitten that was holding a fish PROVOKED I...    N   \n",
      "364                       Minor injury to arm by a fish    N   \n",
      "393                              Puncture wounds to leg    N   \n",
      "403                Minor injury to ankle from stingray     N   \n",
      "697                          Injuries to hands and legs    N   \n",
      "997                                      Injury to hand  NaN   \n",
      "5497                                              FATAL    Y   \n",
      "6338                                              FATAL    Y   \n",
      "6819                                              FATAL    Y   \n",
      "6820                                              FATAL    Y   \n",
      "\n",
      "                                               Species   \n",
      "191                                                 NaN  \n",
      "207                                      Bull shark, 3m  \n",
      "228                                                 NaN  \n",
      "233                               No shark invovlement   \n",
      "254                                                 NaN  \n",
      "342                     Shark involvement not confirmed  \n",
      "347                      Injuries not caused by a shark  \n",
      "351                     Shark involvement not confirmed  \n",
      "354                                      4' to 5' shark  \n",
      "364                                                 NaN  \n",
      "393   Shark involvement unconfirmed but considered p...  \n",
      "403                                                 NaN  \n",
      "697                                                 NaN  \n",
      "997                                                 NaN  \n",
      "5497                                                NaN  \n",
      "6338                                                NaN  \n",
      "6819                                                NaN  \n",
      "6820                                                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Visualizar los valores faltantes\n",
    "print(df[df['Type'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modificar Type los valores nan, '?', Invalid por NAN\n",
    "df['Type'] = df['Type'].replace(['nan', '?', 'Invalid'], 'NaN')  \n",
    "\n",
    "\n",
    "#Reemplazar ' Provoked' por 'Provoked'\n",
    "df['Type'] = df['Type'].replace({' Provoked': 'Provoked'})\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Type'] = df['Type'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar minusculas por mayusculas\n",
    "df['Type'] = df['Type'].str.upper()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Type'] = df['Type'].replace({''}, 'NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['AUSTRALIA' 'USA' 'INDIA' 'TRINIDAD' 'BAHAMAS' 'SOUTH AFRICA' 'MEXICO'\n",
      " 'NEW ZEALAND' 'EGYPT' 'Mexico' 'BELIZE' 'PHILIPPINES' 'Coral Sea' 'SPAIN'\n",
      " 'PORTUGAL' 'SAMOA' 'COLOMBIA' 'ECUADOR' 'FRENCH POLYNESIA'\n",
      " 'NEW CALEDONIA' 'TURKS and CaICOS' 'CUBA' 'BRAZIL' 'SEYCHELLES'\n",
      " 'ARGENTINA' 'FIJI' 'MeXICO' 'Maldives' 'South Africa' 'ENGLAND' 'JAPAN'\n",
      " 'INDONESIA' 'JAMAICA' 'MALDIVES' 'THAILAND' 'COLUMBIA' 'COSTA RICA'\n",
      " 'New Zealand' 'British Overseas Territory' 'CANADA' 'JORDAN'\n",
      " 'ST KITTS / NEVIS' 'ST MARTIN' 'PAPUA NEW GUINEA' 'REUNION ISLAND'\n",
      " 'ISRAEL' 'CHINA' 'IRELAND' 'ITALY' 'MALAYSIA' nan 'MAURITIUS'\n",
      " 'SOLOMON ISLANDS' 'ST HELENA, British overseas territory' 'REUNION'\n",
      " 'UNITED KINGDOM' 'UNITED ARAB EMIRATES' 'CAPE VERDE' 'Fiji'\n",
      " 'DOMINICAN REPUBLIC' 'CAYMAN ISLANDS' 'ARUBA' 'MOZAMBIQUE' 'PUERTO RICO'\n",
      " 'ST. MARTIN' 'FRANCE' 'TRINIDAD & TOBAGO' 'KIRIBATI' 'DIEGO GARCIA'\n",
      " 'TAIWAN' 'PALESTINIAN TERRITORIES' 'GUAM' 'NIGERIA' 'TONGA' 'SCOTLAND'\n",
      " 'SAUDI ARABIA' 'CHILE' 'ANTIGUA' 'KENYA' 'RUSSIA' 'TURKS & CAICOS'\n",
      " 'UNITED ARAB EMIRATES (UAE)' 'AZORES' 'SOUTH KOREA' 'MALTA' 'VIETNAM'\n",
      " 'MADAGASCAR' 'PANAMA' 'SOMALIA' 'NEVIS' 'CROATIA'\n",
      " 'BRITISH VIRGIN ISLANDS' 'NORWAY' 'Sierra Leone' 'ATLANTIC OCEAN'\n",
      " 'ST. MAARTIN' 'GRAND CAYMAN' 'Seychelles' 'LIBERIA' 'VANUATU' 'MEXICO '\n",
      " 'HONDURAS' 'VENEZUELA' 'SRI LANKA' ' TONGA' 'URUGUAY' 'MICRONESIA'\n",
      " 'OKINAWA' 'TANZANIA' 'MARSHALL ISLANDS' 'SENEGAL' 'EGYPT / ISRAEL'\n",
      " 'NORTHERN ARABIAN SEA' 'HONG KONG' 'EL SALVADOR' 'CARIBBEAN SEA' 'ANGOLA'\n",
      " 'BERMUDA' 'GREECE' 'TUNISIA' 'NAMIBIA' 'NORTH ATLANTIC OCEAN'\n",
      " 'SOUTH CHINA SEA' 'WESTERN SAMOA' 'PACIFIC OCEAN ' 'BRITISH ISLES'\n",
      " 'PALAU' 'GRENADA' 'IRAQ' 'TURKEY' 'SINGAPORE' 'NEW BRITAIN' 'SUDAN'\n",
      " 'JOHNSTON ISLAND' 'SOUTH PACIFIC OCEAN' 'NEW GUINEA' 'RED SEA'\n",
      " 'NORTH PACIFIC OCEAN' 'FEDERATED STATES OF MICRONESIA'\n",
      " 'MID ATLANTIC OCEAN' 'ADMIRALTY ISLANDS' 'BRITISH WEST INDIES'\n",
      " 'SOUTH ATLANTIC OCEAN' 'PERSIAN GULF' 'RED SEA / INDIAN OCEAN'\n",
      " 'PACIFIC OCEAN' 'NORTH SEA' 'MALDIVE ISLANDS' 'AMERICAN SAMOA'\n",
      " 'ANDAMAN / NICOBAR ISLANDAS' 'GABON' 'MAYOTTE' 'NORTH ATLANTIC OCEAN '\n",
      " 'MONTENEGRO' 'YEMEN' 'THE BALKANS' 'SUDAN?' 'IRAN' 'GUATEMALA'\n",
      " 'NETHERLANDS ANTILLES' 'NORTHERN MARIANA ISLANDS' 'IRAN / IRAQ'\n",
      " 'SIERRA LEONE' ' PHILIPPINES' 'CENTRAL PACIFIC' 'INDIAN OCEAN'\n",
      " 'SOLOMON ISLANDS / VANUATU' 'SOUTHWEST PACIFIC OCEAN' 'BAY OF BENGAL'\n",
      " 'ICELAND' 'ITALY / CROATIA' 'NICARAGUA' 'MONACO' 'GUYANA' 'BARBADOS'\n",
      " 'HAITI' 'SAN DOMINGO' 'KUWAIT' 'YEMEN ' 'FALKLAND ISLANDS' 'CRETE'\n",
      " 'CYPRUS' 'LIBYA' 'EGYPT ' 'WEST INDIES' 'BURMA' 'LEBANON' 'MARTINIQUE'\n",
      " 'BRITISH NEW GUINEA' 'CEYLON' 'GEORGIA' 'SYRIA' 'INDIAN OCEAN?' 'GUINEA'\n",
      " 'EQUATORIAL GUINEA / CAMEROON' 'COOK ISLANDS' 'TOBAGO' 'PERU' 'AFRICA'\n",
      " 'ALGERIA' 'Coast of AFRICA' 'TASMAN SEA' 'GHANA'\n",
      " 'Between PORTUGAL & INDIA' 'BAHREIN' 'KOREA' 'RED SEA?'\n",
      " 'MEDITERRANEAN SEA' 'ASIA?' 'CEYLON (SRI LANKA)']\n",
      "\n",
      "Valores faltantes:\n",
      "38\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Country'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Country'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Country'] = df['Country'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['Country'] = df['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Queensland' 'Hawaii' 'Western Australia' 'Maharashtra' nan\n",
      " 'New  South Wales' 'Paradise Island' 'South Australia'\n",
      " 'Eastern Cape Province' 'Sonora' 'New South Wales' 'South Island'\n",
      " 'Guerrero' 'New Providence   Isoad' 'Jalisco' 'Grand  Bahama Island'\n",
      " 'Florida' 'Westerm Australia' 'North Island' 'Southern Red Sea'\n",
      " 'Quintana Roo' 'Belize District' 'California' 'South Carolina'\n",
      " 'South Sinai' 'Bolinao' 'Valencia' 'Norte' \"Savai'i island\" 'New York'\n",
      " 'San Andrés Island' 'Galapagos Islands' 'Red Sea Protectorate' 'Freeport'\n",
      " 'Tahiti' 'Poum' 'Providenciales Island' 'Lucayan Lucayan Archipelago'\n",
      " 'New Jersey' 'Mayabeque' 'Easten Cape Province' 'Artemisa' 'Pernambuco'\n",
      " 'Praslin Island' 'South Province' 'Patagonia' 'Taveuni Island'\n",
      " 'Gulf of California' 'Vaavu Atoll' 'KNZ' 'New South ales' 'Samoa' 'Texas'\n",
      " 'Louisiana' 'Mississippi' 'Western  Australia' 'Victoria'\n",
      " 'Western Cape Province' 'Cornwall' 'Noirth Carolina' 'Okinawa' 'Bali'\n",
      " 'Hurghada, Red Sea Governorate' 'Ambergris Cay' 'Georgia' 'Phuket'\n",
      " 'Alabama' 'KZN' 'Isla De San Andres' 'Guanacoste' 'KwaZulu-Natal'\n",
      " 'São Paulo.' 'Turks and Caicos' 'Nova Scotia' 'Maryland' 'North Carolina'\n",
      " 'Chanthaburi Province' 'BAHAMAS' 'Galapagos' 'Aqaba' 'West Sussex'\n",
      " 'Nouville' 'Ambergris Key' 'Westmoreland Parish' 'Marquesas'\n",
      " 'Loyalty Islands' 'Maui' 'The Narrows' 'Raa Atoll' 'Oregon'\n",
      " ' Grand Bahama Island' 'Franklin County, Florida' 'Virgin Islands'\n",
      " 'Tuamotu Islands' 'Maine' 'Bahamas' 'Tasmania' 'Delaware' 'Abaco Islands'\n",
      " 'Muang district of Satun province, ' 'Canary Islands' 'Vanua Levu'\n",
      " 'Exumas' 'Southland' 'Phang Nga Province' 'Praslin' 'Central Province'\n",
      " 'Holquin' 'Moorea' 'Baja ' 'Saint-Gilles' 'Guam' 'Northern Territory '\n",
      " 'Cayman Islands' 'Rhode Island' 'Chatham Islands' 'Quinta Roo'\n",
      " 'Lucayan Archipelago' 'Bélep Islands' 'Noumea' 'Fernando de Noronha'\n",
      " 'Liaoning Province' 'New South Wales ' 'Upolo' 'St. Marys Parish'\n",
      " 'Massachusetts' 'County Cork' 'Chieti, Province' 'Guizhou Province'\n",
      " 'San Andres and Providencia Archipelago' 'The Exuma Cays' 'Colima'\n",
      " 'Hua Hin' 'Cocos Island' 'Alifu Alifu Atoll' 'New Providence' 'Alagoas'\n",
      " 'Boi Island, Victoria' 'Sepang' 'Holquin Province' 'Pamplemousses '\n",
      " ' Upolu Island' 'Shizuoka Prefecture' 'Castellón'\n",
      " 'New Providence District' '40 miles off Grand Bahama Island'\n",
      " 'Ascension Island' 'Majorca' 'Washington' 'Tabasco' 'Ibiza Island'\n",
      " 'South Devon' 'New Providence ' 'Sharjah, ' 'Baja California Sur'\n",
      " 'Saint-Leu' 'Luzon Island' 'Tamaulipas' 'Saint-Andre' 'Bimini' 'Tuamotos'\n",
      " 'North Province' 'New Providence Island' 'Alicante Province' 'Hong Kong'\n",
      " 'Kochi Prefecture' 'Isla Providencia' 'Suez' 'Grand Terre'\n",
      " 'Boa Vista Island' 'Santa Catarina State' 'Altagracia Province'\n",
      " 'Grand Cayman' 'Balneário Camboriú' 'Fujairah Emirate'\n",
      " 'Grand Canary Island' 'Inhambane Province' 'Alicante' 'Guanacaste'\n",
      " 'Bora Bora' 'Grand Bahama Island' 'Le Port' 'Rangiroa'\n",
      " 'Saint-Gilles-les-Bains' 'Sardinia' 'Sinaloa' 'Central Tuamotu'\n",
      " 'd’Étang-Salé' 'Granada' 'Cargados Carajos Shoals (St. Brandon)'\n",
      " 'Catalonia' 'West End' 'Atsumi peninsula' 'Palmyra Atoll'\n",
      " 'Wallis and Futuna' 'Baie de Sainte-Marie' 'Society Islands' 'Trinidad'\n",
      " 'Okinawa Prefecture' '740 miles SE of Tarawa Atoll' 'Southern District'\n",
      " 'Bay of Biscay' 'Exuma Islands' 'Saint-Paul' 'Taitung ' 'Kingston Parish'\n",
      " 'Santa Cruz Island' 'Tuamotus' 'Eleuthera' 'St. Catherine' 'Palawan'\n",
      " 'Mercury Islands' 'Delta' \"Vava'u\" 'Inner Hebrides' 'Saint Leu'\n",
      " 'Trois-Bassins' 'British Colombia' 'Saint-Benoit' 'Tabuk Province'\n",
      " 'Antofagasta Province' \"St John's\" 'Santa Elena' 'East New Britain'\n",
      " 'Bois-Blanc ' 'Moray' 'Puerto Rico' 'Samaná Province' 'Coast Province'\n",
      " 'Primorsky Krai' 'Peter the Great Bay, Khasan, Primorsky Krai (Far East)'\n",
      " 'Telyakovsky Bay, Khasan,  Primorsky Krai (Far East)' 'Sucre'\n",
      " 'Middle Caicos' 'Caicos Bank' 'San Andrés archipelago' 'Kedah'\n",
      " 'Umm al Qaywayan Province' 'Vitu Levu' 'South Sinai Peninsula'\n",
      " ' Loyalty Islands' 'Saint Gilles ' 'Virginia' \"Ha'api \"\n",
      " 'Western Province' 'Jeju Province' 'Binh Dinh Province'\n",
      " 'Antsiranana Province' 'Sinai Peninsula' 'Off Vanua Levu' 'Merizo'\n",
      " 'Rio Grande Do Sul' 'Dubai' 'Torres Strait' 'Eastern Province'\n",
      " 'Eastern Cape  Province' 'Maputo Province' 'Bocas' 'Fife' 'Devon'\n",
      " 'Makira-Ulawa Province' 'Mombasa' 'Catalunya' 'St. Johns Reef'\n",
      " 'Off Green Island' 'North Region' 'Batangas province' 'Strait of Malacca'\n",
      " 'Guantanamo Province' 'Maranhão' 'Red Sea' 'Batanes Provine' 'Luzon'\n",
      " 'Northern Territory' ' Split-Dalmatia Count,' 'North Devon'\n",
      " 'US Virgin Islands' 'San Carlos' 'Cabo San Lucas' 'Sussex' 'Bahia'\n",
      " 'Guerro' 'Yasawa Islands' 'Northern Bahamas' 'Tokyo Bay'\n",
      " 'Baja California' 'Green Bay' 'Marovo Lagoon'\n",
      " 'Territory of Cocos (Keeling) Islands' 'Oslo Fjord' 'Kent' 'Bird Island'\n",
      " 'Bimini Islands' 'Cook islans' 'Ambergris Caye' 'Saint-Pierre'\n",
      " 'Andros Islands' 'Western Area' '300 miles from Antigua'\n",
      " '800 miles from land' 'Simpson Bay' 'East Wall' 'Inner Islands'\n",
      " 'Shanghai' 'Malampa Province' \"South Ch'ungch'ong Province\" 'Bay Islands'\n",
      " 'New Mexico' 'Santa Isabel Province' 'Santiago de Cuba Province'\n",
      " 'Camaguey Province' 'Conservatória District' 'South Carolina '\n",
      " 'Kuril Islands in the Pacific' 'Wakayama Prefecture' \"Nuku'alofa\"\n",
      " 'Saint-Benoît' 'South Island, near Karitane north of Dunedin' 'Rocha'\n",
      " 'Northlands' 'Anzoategui' 'Cook Islands' 'Tamil Nadu' 'Pearl Islands'\n",
      " 'Taveuni' 'Johnston Atoll' 'Rio de Janeiro' 'Nueva Esparta'\n",
      " 'North Pacific coast' 'Caroline Islands' 'Cheshire'\n",
      " 'KwaZulu-Natal between Port Edward and Port St Johns'\n",
      " 'Milne Bay Province' 'Cikobia Island (north of Vanua Levu)'\n",
      " 'Rayong Province' 'Zamboanga del Sur Province' 'Rio Grande de Norte'\n",
      " 'Off the western coast of peninsular Malaysia' 'New Brunswick'\n",
      " 'Miyako Island' 'Alaska' 'Minerva Reef' 'Madang Province'\n",
      " 'Worcestershire' 'Phang nga Province' 'Alinglaplap Atoll' 'Ralik Chain'\n",
      " 'Grand Baie' \"L' Etang Salé-les-Bains\" 'Southern Japan'\n",
      " 'Cap Vert Peninsula' 'Berry Islands' 'Transvaal' 'Gaza' \"Grand'Anse\"\n",
      " 'Miyako' \"L'Etang-Sale\" 'Chatham Islands ' 'South Sinai, Gulf of Aqaba'\n",
      " 'Cat Cay' 'Missouri' 'Saint-Paul '\n",
      " 'Chatham Islands, east of New  Zealand' 'Saint-Denis' 'Vava’u'\n",
      " 'Clearwater Bay' 'New Territories' 'Aichi Prefecture' 'Banaadir Region'\n",
      " 'La Libertad' 'Costa Blanca' 'Walkers Cay'\n",
      " 'On the Kowloon penisula, south of Sai Kung' 'Tongapatu Group'\n",
      " 'West Africa' 'Wakaya Island' 'North Carolina ' 'Saint-Joseph'\n",
      " 'Mexico / Caribbean Sea' 'Antarctic Ocean' 'Ehime Prefecture'\n",
      " 'La Saline-les-Bains' 'Ligurian Sea' \"L'Etang-Salé\" 'Kowloon Peninsula'\n",
      " 'Port Shelter' 'Laucala Island' 'Sainte-Marie' 'Great Exuma Island'\n",
      " 'Sainte-Suzanne' 'Tuscany' 'Sea of Japan' 'Tyrrhenian Sea'\n",
      " 'Valpariso Province' 'New Ireland' 'Manfredonia ' 'Tokyo Prefecture'\n",
      " 'Saint-Louis' 'Florida Straits' 'Cádiz' 'Sicily' 'Andikira Fokithes'\n",
      " 'Central Philippines' 'Northwest Italy' 'English Channel'\n",
      " 'Carolina coast' 'Kumamoto Prefecture' 'Saint-Philippe' 'Chungnam'\n",
      " 'Eronogo Region' 'Coquimbo' 'Pagasitikos Gulf' \"St. Mary's Parish\"\n",
      " 'Lamu Archipelago' 'Los Vilos' 'Island of Kos' \"Ha'api\" 'Madeira Islands'\n",
      " 'Ho Ha Wan Marine Park' 'Southern Thailand' 'Ralik Archipelago'\n",
      " 'South China Sea 200 miles from Hong Kong' 'Reggio Calabria Province'\n",
      " 'Mirs Bay ' 'Genoa Province' ' Split-Dalmatia County' 'Florida '\n",
      " 'Upolu Island' 'Istria County' 'Inhambe Province' 'Namonuito Atoll'\n",
      " 'Eastern Caroline Islands'\n",
      " 'Western Caroline Islands (North Pacific Ocean)' 'St. Andrew Parish'\n",
      " 'Limpopo River' 'New Ireland Province' 'Basrah' 'Clarendon'\n",
      " 'Magdalena Department' 'Gulf Province' 'Brindisi Province'\n",
      " 'Kagawa Prefecture' 'Liguria' 'Hamilton' 'Out Islands' 'Mugla Province'\n",
      " 'Gibraltar' 'New Britain' 'Veracruz' 'Bay of Maputo'\n",
      " 'Duke of York Islands' 'Primorje-Gorski Kotar County ' 'Taranto province'\n",
      " 'Northern Taiwan' 'Admiralty Islands, Manus Province'\n",
      " \"250 miles southwest of O'ahu, Hawaii\" 'West coast' 'East Sepik'\n",
      " 'Near Bougainville (North Solomons)' 'Western Caroline Islands'\n",
      " 'East of the Gulf of Aqaba' 'Bougainville (North Solomons)' 'Victoria '\n",
      " 'Okayama Prefecture' 'San Blas' 'Lau Group' 'Caribbean Coast' 'Vita Levu'\n",
      " 'San Blas Islands' 'Puntarenas Province' 'Lomaloma, Lau'\n",
      " 'Between Southampton & Canary Islands' 'South Coast, East New Britain'\n",
      " ' Lau Province' 'Ysabel Island' 'Santo Domingo' 'San Blas coast'\n",
      " 'Thessaly' 'Lomaiviti  Island Group' 'Rodrigues' 'Manus Island'\n",
      " 'Pinas Bay' 'Grand Turk Island' 'Off coast of West Africa' 'Sharon'\n",
      " 'Antalya Province' 'Northern District'\n",
      " 'New Ireland Province, Bismarck Archipelago'\n",
      " 'Off the Coromandel Peninsula, North Island' 'Madang'\n",
      " 'Guadalcanal Province' '10ºS, 142ºE' 'Kwajalein Atoll'\n",
      " 'Western Luzon Island' 'Shefa Province' '165  miles from Bermuda'\n",
      " '25 km off the coast of Iran & 483km from mouth of Persian Gulf'\n",
      " 'Venice Province' 'Sandaun Province' 'Anatolia' 'Adriatic Sea'\n",
      " 'East New Britain Province' 'Wake Island (EnenKio)' '19S, 178?E'\n",
      " 'Pennsylvania' 'Roncador Bank' 'Western District'\n",
      " 'Enroute from Suez to Aden (Yemen)' '180 miles southeast of Okinawa'\n",
      " 'Eniwetok Atoll' 'Connecticut' 'In the English Channel '\n",
      " 'Unknown, treated at Wick, SCOTLAND' 'Corregidor Island' 'Paget'\n",
      " '33N, 68W' 'Casamance' 'Madang (WO)' 'Eastern  Province'\n",
      " 'Northwest of Viti Levu' 'Masbate' '400 miles southeast of Sri Lanka'\n",
      " 'Lomaiviti Province' 'Kadavu' 'Leyte Island' 'Guerrrero'\n",
      " 'Hokkaido Prefecture' 'North Palawan' 'Istria' 'Mersin Province'\n",
      " 'Guyamas' 'Between England & South Africa' 'Mindanao'\n",
      " ' Kikori River mouth' 'South Chungcheong Province' 'Tutuila Island'\n",
      " 'West New Britain Province' 'Primorje-Gorski Kotar County'\n",
      " 'Between Hawaii & Wake Island' 'Taipei Hsien' 'Morobe Province'\n",
      " 'Ibaraki Prefecture' 'Honiara' 'Viti Levu' 'Estuaire Province'\n",
      " 'Near Dakar, Cap Vert Peninsula' 'Near the Andaman & Nicobar Islands'\n",
      " 'Mozambique Channel' 'Tyrrenian Sea' 'St. Thomas Bay' 'Madeira'\n",
      " '1000 miles west of Hawaii' 'Izo Islands' ' Primorje-Gorski Kotar County'\n",
      " 'Open sea' 'Aden' 'New Ireland, Bismarck Archipelago' 'Isles del Rosario'\n",
      " 'Wake Island' 'Isle of Man' 'Nagasaki Prefecture' 'Slovenia'\n",
      " 'South shore ' 'Buenos Aires Province' 'Karun River' 'Gulf of Panama'\n",
      " 'Genoa  Province' 'Abau Sub District, Central Province' 'Red Sea State'\n",
      " 'Curacao' 'Port Louis Province' 'Montserrado' 'Bay of Maputu'\n",
      " 'Sofala Province' 'Salerno' 'Salerno Province' 'Corfu Island' 'Taranto'\n",
      " ' La Libertad' 'Sago Prefecture' 'Caribbean Sea' 'Jakarta Harbour'\n",
      " 'Calabria' 'Shatt-el-Arab River' 'Shatt-al-Arab River'\n",
      " 'Shat-Al-Arab River' 'Between Kwajalein Atoll & Johnston Island' 'Attica'\n",
      " 'Adana Province' 'Bandar Ma’shur sea inlet' 'Saipan' 'Carpathian Sea'\n",
      " 'Kwajalein' 'Khuzestan Province' 'Dar-es-Salaam ' 'Ryukyu' 'Tel Aviv'\n",
      " '300 miles east of Luzon' 'Bernardino Strait near Gulf of Leyte'\n",
      " 'Off Samar Island in the Gulf of Leyte' 'Near the Fiji Islands'\n",
      " '40 miles south of Naples ' 'Northwest of Papua New Guinea'\n",
      " 'Between Hawaii and U.S.A.' 'Off South American coast'\n",
      " 'Makora-Ulawa Province' 'Midway Atoll'\n",
      " '300 miles east of St. Thomas (Virgin Islands)' 'Camiguin Island'\n",
      " 'Off Libya' 'Off coast of Ecuador' 'Trelawney Province'\n",
      " 'In Convoy OB 274' 'Panama Bay (Pacific Ocean)' 'Torres Strait '\n",
      " 'North China' 'Nicoya Peninsula' 'Basrah City' 'Queensland ' 'Argyll'\n",
      " 'Colon Province' 'Fishing Grounds' 'Isle of Wight'\n",
      " 'Makira-Uluwa Province' 'Elqui Province' 'Istanbul' 'Havana Province'\n",
      " 'Barlavento Islands' 'Viti Levu Island' 'Bay of Fundy' 'Manila'\n",
      " 'French Southern Territories' 'Black River' 'Phoenix Islands'\n",
      " 'Cienfuegos Province' 'Santiago Island' 'Near Puntarenas' 'Salinas Bay'\n",
      " 'Golfo di Genova in the Ligurian Sea' 'Sants-Montjic'\n",
      " 'South of the Equator ' 'Bay of Monaco' 'Valencia ' 'Vancouver'\n",
      " '2 to 3 miles off Taboguilla Island, Pacific Ocean' 'Dorset'\n",
      " '150 miles offshore' 'Demerara County' ' Manila Bay' 'Lucy'\n",
      " 'East Yorkshire' 'Cape Haitien' 'Leyte' 'Turtle Bogue'\n",
      " '60 miles north of San Domingo in the West Indies' 'Colon' 'Off Ireland'\n",
      " 'Gran Canaria' 'Apolima Strait' 'Zadar County' 'Essequibo' 'Lagos '\n",
      " 'Viti Levu group' 'Málaga ' 'Georges Bank' 'Colón Province' 'Andalucia'\n",
      " 'Sfax' 'South Atlantic Ocean' 'Galicia' 'Gulf of Suez' 'Java'\n",
      " 'Tiburon Peninsula' 'Oaxaca' 'Harare Province' 'Maluku Province'\n",
      " 'Suez Canal' ' Nusa Tenggara' 'Between Noumea & Sydney'\n",
      " 'Villa Clara Province' 'Ancona Province' 'Rio San Juan'\n",
      " 'Mediterranean Sea' 'Southern Cyprus' 'Syracuse' 'Western Viscayas'\n",
      " 'Negros ' 'Imperia Province' 'Muala' 'East coast' 'Vera Cruz'\n",
      " 'St Michael Parish' 'Moluccas' 'Bocas del Toro' 'Provence'\n",
      " 'Bay of Campeche' 'Rangoon' 'Bay of Bengal' 'Bayelsa State'\n",
      " 'South Island?' 'Norfolk Island' 'Woodlark Islands' 'Munxar Reef'\n",
      " 'Between Perth & Colombo' 'Gujarat' 'Cortés' ' New Jersey'\n",
      " \"Côte d'Azur  \" 'Maldonado coast' 'Western Banks' 'West Bengal'\n",
      " 'Andaman Islands' 'East Java' 'Off the coast of West Africa'\n",
      " 'Misamis Oriental' 'Strait of Messina' 'Hoogly River'\n",
      " 'Cyclades archipelago' 'Veracruz ' 'Gilbert Islands' 'Newfoundland'\n",
      " 'Lomaiviti Provine' 'Off the coast of South America' '22ºN, 88ºE'\n",
      " 'Alpes Maritime' 'Edinburgh' 'Eastern Catalona'\n",
      " '300 miles east of Mauritius' 'Foveaux Strait' 'Conakry Region' 'Corfu'\n",
      " 'Malaga' 'Fernando Po Island' 'Mangaia Island' 'New York ' 'Corfu '\n",
      " 'Between Australia & USA' 'Tongatapu' 'Norfolk' 'Island of St. Thomas'\n",
      " 'Matanzas Province (north coast)' 'Cumberland' 'Sanma Province'\n",
      " \"35º39 : 165º8'\" 'CUBA' 'Western Area ' 'Paraiba' 'Cape Coast'\n",
      " 'St Helena' 'Southwest coast' \"Côte d'Azur \" 'Nice & Marseilles'\n",
      " 'Magarita or Cubagua Islands' 'Yucatan' 'Ionian Sea' 'Piraeus'\n",
      " 'Off Thessaly' 'Paloma' 'Bocas del Toro Province' 'Rocha ' 'Cyrenaica'\n",
      " 'Northern Province' 'Los Roques  Islands' 'Dodecanese Islands'\n",
      " 'Malaita Province' 'South Korea' 'Milne Bay  Province' 'Island of Volos'\n",
      " 'Amirante Islands' 'Kadavu Island Group' 'Toamasina Province'\n",
      " 'Riau Province' 'Lake Nicaragua (fresh water)' 'Bikini Atoll'\n",
      " 'New Georgia' 'Between New Ireland & New Britain'\n",
      " 'Ba Ria-Vung Tau  Province']\n",
      "\n",
      "Valores faltantes:\n",
      "381\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['State'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['State'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['State'] = df['State'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['State'] = df['State'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['State'] = df['State'].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Bargara Beach' \"Old Man's, Waikiki\" 'Rainbows, Oahu' ...\n",
      " 'Ocracoke Inlet' 'Panama Bay 8ºN, 79ºW'\n",
      " 'Below the English fort, Trincomalee']\n",
      "\n",
      "Valores faltantes:\n",
      "439\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Location'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Location'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Reemplazar minisculas por mayusculas\n",
    "df['Location'] = df['Location'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['Location'] = df['Location'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Location'] = df['Location'].replace({''}, 'NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Swimming' 'Surfing' nan ... 'Swimming around anchored ship'\n",
      " 'Crew swimming alongside their anchored ship' '4 men were bathing']\n",
      "\n",
      "Valores faltantes:\n",
      "381\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity     381\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Activity'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Activity'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Activity'] = df['Activity'].str.upper()\n",
    "\n",
    "# Eliminar espacios en las celdas\n",
    "df['Activity'] = df['Activity'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Activity'] = df['Activity'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar los valores que no sean 'SURFING', 'SWIMMING' o 'FISHING' por NaN\n",
    "valid_activities = ['SURFING', 'SWIMMING', 'FISHING']\n",
    "df['Activity'] = df['Activity'].apply(lambda x: x if x in valid_activities else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['13' nan '11' '46' '32' '29' '10' '64' '62' '39' '22' '15' '16' '21' '66'\n",
      " '52' '20' '44' '26' '47' '55' '30' '59' '8' '50' '45' '34' '38' '30s'\n",
      " '37' '19' '20/30' '35' '65' '20s' '77' '60' 38 '49' '42' '!2' '24' '73'\n",
      " '25' '18' '50s' '58' '67' '17' '14' '6' '41' '53' '68' '43' '40' '51'\n",
      " '31' 39 26 58 51 14 17 10 13 33 16 40 49 41 60 28 '40s' 68 35 62 'teen'\n",
      " 20 8 22 32 56 'Teen' 12 21 42 36 18 37 50 'M' 9 24 15 11 27 57 34 25 '!6'\n",
      " 31 64 '!!' 47 55 19 7 71 48 59 53 54 75 '45 and 15' 46 61 73 52 29 30 70\n",
      " 23 4 63 45 44 '28 & 22' '60s' \"20's\" 43 65 67 74 '9 & 60' 'a minor' 6 69\n",
      " 3 82 66 72 '23' '12' '9' '36' '63' '71' '48' '70' '18 months' '57' '7'\n",
      " '28' '33' '61' '74' '27' '3' '56' '28 & 26' '5' '54' '86' '18 or 20'\n",
      " '12 or 13' '46 & 34' '28, 23 & 30' 'Teens' 77 '8 or 10' 84 '\\xa0 ' ' '\n",
      " '30 or 36' '6½' '21 & ?' '33 or 37' 'mid-30s' '23 & 20' 5 ' 30'\n",
      " '7      &    31' ' 28' '20?' \"60's\" '69' '32 & 30' '16 to 18' '87'\n",
      " 'Elderly' 'mid-20s' 'Ca. 33' '74 ' '45 ' '21 or 26' '20 ' '>50'\n",
      " '18 to 22' 'adult' '? & 19' '9 months' '25 to 35' '23 & 26' 1 '(adult)'\n",
      " '33 & 37' '25 or 28' '37, 67, 35, 27,  ? & 27' '21, 34,24 & 35' '30 & 32'\n",
      " '17 & 35' 'X' '\"middle-age\"' '13 or 18' '33 & 26' '4' ' 43' '81'\n",
      " '\"young\"' '7 or 8' 78 'F' 'Both 11' '9 or 10' 'young' '36 & 23' '  ' '78'\n",
      " 'A.M.' '?    &   14' '10 or 12' '31 or 33' '2½' '1' '13 or 14']\n",
      "\n",
      "Valores faltantes:\n",
      "2249\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity    3666\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         2249\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Age'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Age'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar espacios en las celdas\n",
    "df['Age'] = df['Age'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Age'] = df['Age'].replace({''}, 'NaN')\n",
    "\n",
    "# Convertir la columna 'Age' a numérica, con valores no numéricos convertidos a NaN\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Minor injuries to back, abdomen and legs'\n",
      " 'No injury, shark bit surfboard' 'Lacerations to left foot' ...\n",
      " 'FATAL, leg stripped of flesh  '\n",
      " 'FATAL, knocked overboard by tail of shark & carried off by shark '\n",
      " 'FATAL. \"Shark bit him in half, carrying away the lower extremities\" ']\n",
      "\n",
      "Valores faltantes:\n",
      "15\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity    3666\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         4325\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Injury'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Injury'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar espacios en las celdas\n",
    "df['Injury'] = df['Injury'].str.strip()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Injury'] = df['Injury'].replace({''}, 'NaN')\n",
    "\n",
    "# Reemplazar minusculas por mayusculas\n",
    "df['Injury'] = df['Injury'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['Tiger shark' \"Tiger shark 8'\" \"3' to 4' shark\" ... 'Blue pointer'\n",
      " 'Blue pointers'\n",
      " 'Said to involve a grey nurse shark that leapt out of the water and  seized the boy but species identification is questionable']\n",
      "\n",
      "Valores faltantes:\n",
      "2703\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity    3666\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         4325\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Species '].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Species '].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar minisculas por mayusculas\n",
    "df['Species '] = df['Species '].str.upper()\n",
    "\n",
    "# Reemplazar celdas vacias por NAN\n",
    "df['Species '] = df['Species '].replace({''}, 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "['TIGER SHARK' \"TIGER SHARK 8'\" \"3' TO 4' SHARK\" ... 'BLUE POINTER'\n",
      " 'BLUE POINTERS'\n",
      " 'SAID TO INVOLVE A GREY NURSE SHARK THAT LEAPT OUT OF THE WATER AND  SEIZED THE BOY BUT SPECIES IDENTIFICATION IS QUESTIONABLE']\n",
      "\n",
      "Valores faltantes:\n",
      "2703\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           2\n",
      "Type          18\n",
      "Country       38\n",
      "State        381\n",
      "Location     439\n",
      "Activity    3666\n",
      "Name          65\n",
      "Sex            0\n",
      "Age         4325\n",
      "Injury        15\n",
      "Died         461\n",
      "Species     2703\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Valores unicos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Species '].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Species '].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELIMINAMOS DUPLICADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Year           2\n",
       "Type          18\n",
       "Country       38\n",
       "State        381\n",
       "Location     439\n",
       "Activity    3664\n",
       "Name          65\n",
       "Sex            0\n",
       "Age         4323\n",
       "Injury        15\n",
       "Died         461\n",
       "Species     2702\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Valores nulos\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminamos las filas de 1642 para atras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas de menos del year 1700\n",
    "df = df[df['Year'] >= 1700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores unicos:\n",
      "[nan 'N' 'Y' 'NaN' 'NQ' 'Y X 2']\n",
      "\n",
      "Valores faltantes:\n",
      "458\n",
      "\n",
      "Valores faltantes por columna:\n",
      "Date           0\n",
      "Year           0\n",
      "Type          16\n",
      "Country       35\n",
      "State        356\n",
      "Location     404\n",
      "Activity    3556\n",
      "Name          64\n",
      "Sex            0\n",
      "Age         4201\n",
      "Injury        13\n",
      "Died         458\n",
      "Species     2610\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores unicos y visualizarlos\n",
    "print(\"\\nValores unicos:\")\n",
    "print(df['Died'].unique())\n",
    "print(\"\\nValores faltantes:\")\n",
    "print(df['Died'].isnull().sum())\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: 09 Sep- 2023, at position 42",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Creamos una nueva columna llamada Month\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDatetimeIndex(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmonth\n",
      "File \u001b[1;32mc:\\Users\\thaty\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:368\u001b[0m, in \u001b[0;36mDatetimeIndex.__new__\u001b[1;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[0;32m    365\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_simple_new(data, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 368\u001b[0m dtarr \u001b[38;5;241m=\u001b[39m DatetimeArray\u001b[38;5;241m.\u001b[39m_from_sequence_not_strict(\n\u001b[0;32m    369\u001b[0m     data,\n\u001b[0;32m    370\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    371\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    372\u001b[0m     tz\u001b[38;5;241m=\u001b[39mtz,\n\u001b[0;32m    373\u001b[0m     freq\u001b[38;5;241m=\u001b[39mfreq,\n\u001b[0;32m    374\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m    375\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m    376\u001b[0m     ambiguous\u001b[38;5;241m=\u001b[39mambiguous,\n\u001b[0;32m    377\u001b[0m )\n\u001b[0;32m    378\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (Index, ABCSeries)):\n",
      "File \u001b[1;32mc:\\Users\\thaty\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:339\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;66;03m# DatetimeTZDtype\u001b[39;00m\n\u001b[0;32m    337\u001b[0m         unit \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39munit\n\u001b[1;32m--> 339\u001b[0m subarr, tz, inferred_freq \u001b[38;5;241m=\u001b[39m _sequence_to_dt64ns(\n\u001b[0;32m    340\u001b[0m     data,\n\u001b[0;32m    341\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    342\u001b[0m     tz\u001b[38;5;241m=\u001b[39mtz,\n\u001b[0;32m    343\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m    344\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m    345\u001b[0m     ambiguous\u001b[38;5;241m=\u001b[39mambiguous,\n\u001b[0;32m    346\u001b[0m     out_unit\u001b[38;5;241m=\u001b[39munit,\n\u001b[0;32m    347\u001b[0m )\n\u001b[0;32m    348\u001b[0m \u001b[38;5;66;03m# We have to call this again after possibly inferring a tz above\u001b[39;00m\n\u001b[0;32m    349\u001b[0m _validate_tz_from_dtype(dtype, tz, explicit_tz_none)\n",
      "File \u001b[1;32mc:\\Users\\thaty\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2226\u001b[0m, in \u001b[0;36m_sequence_to_dt64ns\u001b[1;34m(data, copy, tz, dayfirst, yearfirst, ambiguous, out_unit)\u001b[0m\n\u001b[0;32m   2222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m i8data\u001b[38;5;241m.\u001b[39mview(DT64NS_DTYPE), tz, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2224\u001b[0m     \u001b[38;5;66;03m# data comes back here as either i8 to denote UTC timestamps\u001b[39;00m\n\u001b[0;32m   2225\u001b[0m     \u001b[38;5;66;03m#  or M8[ns] to denote wall times\u001b[39;00m\n\u001b[1;32m-> 2226\u001b[0m     data, inferred_tz \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m   2227\u001b[0m         data,\n\u001b[0;32m   2228\u001b[0m         dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   2229\u001b[0m         yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m   2230\u001b[0m         allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   2231\u001b[0m     )\n\u001b[0;32m   2232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz \u001b[38;5;129;01mand\u001b[39;00m inferred_tz:\n\u001b[0;32m   2233\u001b[0m         \u001b[38;5;66;03m#  two timezones: convert to intended from base UTC repr\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\thaty\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2346\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[0m\n\u001b[0;32m   2343\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2344\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2346\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m tslib\u001b[38;5;241m.\u001b[39marray_to_datetime(\n\u001b[0;32m   2347\u001b[0m     data,\n\u001b[0;32m   2348\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   2349\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[0;32m   2350\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   2351\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m   2352\u001b[0m )\n\u001b[0;32m   2354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi8\u001b[39m\u001b[38;5;124m\"\u001b[39m), tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:403\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:552\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:517\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:546\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:331\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:660\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: 09 Sep- 2023, at position 42"
     ]
    }
   ],
   "source": [
    "# Creamos una nueva columna llamada Month\n",
    "df['Month'] = pd.DatetimeIndex(df['Date']).month"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
